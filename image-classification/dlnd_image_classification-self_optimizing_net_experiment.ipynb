{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 4:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1003, 1: 963, 2: 1041, 3: 976, 4: 1004, 5: 1021, 6: 1004, 7: 981, 8: 1024, 9: 983}\n",
      "First 20 Labels: [0, 6, 0, 2, 7, 2, 1, 2, 4, 1, 5, 6, 6, 3, 1, 3, 5, 5, 8, 1]\n",
      "\n",
      "Example of Image 7:\n",
      "Image - Min Value: 17 Max Value: 221\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 2 Name: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCXoAKEzQA0Bhgh4AChP0AFCYoAeAwv4PpDZL2EOvzjYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcaf7edb0f0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 4\n",
    "sample_id = 7\n",
    "batch_size = 5\n",
    "image_sizes = 32\n",
    "image_channels = 3\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_min = np.min(x)\n",
    "    return (x - x_min)/(np.max(x) - x_min)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    encoder = tf.one_hot(x, 10)\n",
    "    encodings = None\n",
    "    with tf.Session() as sess:\n",
    "        encodings = sess.run(encoder)\n",
    "    return encodings\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    height, width, depth = image_shape\n",
    "    return tf.placeholder(tf.float32, [None, height, width, depth], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula\n",
    "\n",
    "$\n",
    "h_{new} = \\frac{h_{ori} - h_{k} + 2P}{s} + 1\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_shape = x_tensor.get_shape().as_list()\n",
    "    stddev = 2 / np.sqrt(x_shape[1] * x_shape[2] * x_shape[3])\n",
    "    w_init = tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_shape[3], conv_num_outputs], stddev=stddev)\n",
    "    W = tf.Variable(w_init)\n",
    "    b = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    conv = tf.nn.conv2d(x_tensor, W, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    conv = tf.nn.bias_add(conv, b)\n",
    "    conv = selu(conv)\n",
    "    pool = tf.nn.pool(conv, [pool_ksize[0], pool_ksize[1]], pooling_type='MAX', strides=[pool_strides[0], pool_strides[1]], padding='VALID')\n",
    "    return pool\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tensor_shape = x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor, [-1, tensor_shape[1]*tensor_shape[2]*tensor_shape[3]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_shape = x_tensor.get_shape().as_list()\n",
    "    stddev = 2 / np.sqrt(x_shape[1])\n",
    "    w_init = tf.truncated_normal([x_shape[1], num_outputs], stddev=stddev)\n",
    "    W = tf.Variable(w_init)\n",
    "    b = tf.Variable(tf.zeros([num_outputs]))\n",
    "    logits = tf.nn.bias_add(tf.matmul(x_tensor, W), b)\n",
    "    return selu(logits)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_shape = x_tensor.get_shape().as_list()\n",
    "    stddev = 2 / np.sqrt(x_shape[1])\n",
    "    w_init = tf.truncated_normal([x_shape[1], num_outputs], stddev=stddev)\n",
    "    W = tf.Variable(w_init)\n",
    "    b = tf.Variable(tf.zeros([num_outputs]))\n",
    "    return tf.nn.bias_add(tf.matmul(x_tensor, W), b)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def future_cost_exp(cost, epoch):\n",
    "    return tf.pow(cost*(1+(epoch+1)*tf.exp(-(epoch+1))-epoch*tf.exp(-epoch)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def future_cost_linear(cost, epoch):\n",
    "    return tf.pow(2*cost+(1/4)*(tf.pow(epoch, 2)-tf.pow(epoch+1, 2)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_1 = conv2d_maxpool(x, 128, [3, 3], [1, 1], [2, 2], [2, 2])\n",
    "    conv_2 = conv2d_maxpool(conv_1, 256, [3, 3], [1, 1], [1, 1], [1, 1])\n",
    "    conv_out = tf.nn.dropout(conv_2, keep_prob)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    conv_flat = flatten(conv_out)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc_1 = fully_conn(conv_flat, 1024)\n",
    "    fc_1_drop = tf.nn.dropout(fc_1, keep_prob)\n",
    "    fc_out = fully_conn(fc_1_drop, 512)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(fc_out, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "cost_epoch = tf.placeholder(tf.float32, name='cost_epoch')\n",
    "cost_predict = future_cost_exp(cost, cost_epoch)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost_predict)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    train_loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
    "    valid_loss = session.run(cost, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.})\n",
    "    train_accuracy = session.run(accuracy, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
    "    valid_accuracy = session.run(accuracy, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.})\n",
    "    print('Loss = Train: {}, Valid: {}'.format(train_loss, valid_loss))\n",
    "    print('Accuracy = Train: {} Valid: {}'.format(train_accuracy, valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "keep_probability = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            sess.run([optimizer], feed_dict={x: batch_features, y: batch_labels, keep_prob: keep_probability, cost_epoch: epoch})\n",
    "        \n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}: \\n'.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1: \n",
      "Loss = Train: 3.141954183578491, Valid: 3.507202625274658\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.18299999833106995\n",
      "Epoch  1, CIFAR-10 Batch 2: \n",
      "Loss = Train: 1.9366474151611328, Valid: 2.074411392211914\n",
      "Accuracy = Train: 0.42500001192092896 Valid: 0.3285999596118927\n",
      "Epoch  1, CIFAR-10 Batch 3: \n",
      "Loss = Train: 1.7150108814239502, Valid: 1.8308324813842773\n",
      "Accuracy = Train: 0.3999999761581421 Valid: 0.3741999566555023\n",
      "Epoch  1, CIFAR-10 Batch 4: \n",
      "Loss = Train: 1.5369436740875244, Valid: 1.6893280744552612\n",
      "Accuracy = Train: 0.42500001192092896 Valid: 0.421999990940094\n",
      "Epoch  1, CIFAR-10 Batch 5: \n",
      "Loss = Train: 1.7899091243743896, Valid: 1.7496554851531982\n",
      "Accuracy = Train: 0.4000000059604645 Valid: 0.4187999665737152\n",
      "Epoch  2, CIFAR-10 Batch 1: \n",
      "Loss = Train: 1.6828938722610474, Valid: 1.5757174491882324\n",
      "Accuracy = Train: 0.5000000596046448 Valid: 0.4519999623298645\n",
      "Epoch  2, CIFAR-10 Batch 2: \n",
      "Loss = Train: 1.389458417892456, Valid: 1.5341259241104126\n",
      "Accuracy = Train: 0.5999999642372131 Valid: 0.46939995884895325\n",
      "Epoch  2, CIFAR-10 Batch 3: \n",
      "Loss = Train: 1.3119858503341675, Valid: 1.5581483840942383\n",
      "Accuracy = Train: 0.574999988079071 Valid: 0.4585999846458435\n",
      "Epoch  2, CIFAR-10 Batch 4: \n",
      "Loss = Train: 1.2916605472564697, Valid: 1.4936283826828003\n",
      "Accuracy = Train: 0.574999988079071 Valid: 0.48239997029304504\n",
      "Epoch  2, CIFAR-10 Batch 5: \n",
      "Loss = Train: 1.445629596710205, Valid: 1.492193579673767\n",
      "Accuracy = Train: 0.550000011920929 Valid: 0.47359994053840637\n",
      "Epoch  3, CIFAR-10 Batch 1: \n",
      "Loss = Train: 1.6285983324050903, Valid: 1.486528754234314\n",
      "Accuracy = Train: 0.4749999940395355 Valid: 0.476999968290329\n",
      "Epoch  3, CIFAR-10 Batch 2: \n",
      "Loss = Train: 1.2151885032653809, Valid: 1.4905608892440796\n",
      "Accuracy = Train: 0.6000000238418579 Valid: 0.4861999750137329\n",
      "Epoch  3, CIFAR-10 Batch 3: \n",
      "Loss = Train: 1.1781775951385498, Valid: 1.5035477876663208\n",
      "Accuracy = Train: 0.6000000238418579 Valid: 0.4873999357223511\n",
      "Epoch  3, CIFAR-10 Batch 4: \n",
      "Loss = Train: 1.1415272951126099, Valid: 1.425569772720337\n",
      "Accuracy = Train: 0.5999999642372131 Valid: 0.49919992685317993\n",
      "Epoch  3, CIFAR-10 Batch 5: \n",
      "Loss = Train: 1.3021728992462158, Valid: 1.4311814308166504\n",
      "Accuracy = Train: 0.6000000238418579 Valid: 0.49919992685317993\n",
      "Epoch  4, CIFAR-10 Batch 1: \n",
      "Loss = Train: 1.5141777992248535, Valid: 1.4075140953063965\n",
      "Accuracy = Train: 0.5500000715255737 Valid: 0.5119999647140503\n",
      "Epoch  4, CIFAR-10 Batch 2: \n",
      "Loss = Train: 1.095536708831787, Valid: 1.4033507108688354\n",
      "Accuracy = Train: 0.625 Valid: 0.5159999132156372\n",
      "Epoch  4, CIFAR-10 Batch 3: \n",
      "Loss = Train: 1.0579952001571655, Valid: 1.5073357820510864\n",
      "Accuracy = Train: 0.625 Valid: 0.4931999742984772\n",
      "Epoch  4, CIFAR-10 Batch 4: \n",
      "Loss = Train: 1.027724266052246, Valid: 1.3599029779434204\n",
      "Accuracy = Train: 0.5999999642372131 Valid: 0.5263999104499817\n",
      "Epoch  4, CIFAR-10 Batch 5: \n",
      "Loss = Train: 1.1887922286987305, Valid: 1.3480331897735596\n",
      "Accuracy = Train: 0.6749999523162842 Valid: 0.5279999375343323\n",
      "Epoch  5, CIFAR-10 Batch 1: \n",
      "Loss = Train: 1.3477911949157715, Valid: 1.391331672668457\n",
      "Accuracy = Train: 0.625 Valid: 0.5143999457359314\n",
      "Epoch  5, CIFAR-10 Batch 2: \n",
      "Loss = Train: 1.0408622026443481, Valid: 1.441756010055542\n",
      "Accuracy = Train: 0.5999999642372131 Valid: 0.48819994926452637\n",
      "Epoch  5, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.9286284446716309, Valid: 1.3099079132080078\n",
      "Accuracy = Train: 0.7250000238418579 Valid: 0.540199875831604\n",
      "Epoch  5, CIFAR-10 Batch 4: \n",
      "Loss = Train: 1.0032382011413574, Valid: 1.3078293800354004\n",
      "Accuracy = Train: 0.675000011920929 Valid: 0.5427999496459961\n",
      "Epoch  5, CIFAR-10 Batch 5: \n",
      "Loss = Train: 1.0732159614562988, Valid: 1.2684268951416016\n",
      "Accuracy = Train: 0.7250000238418579 Valid: 0.5511999726295471\n",
      "Epoch  6, CIFAR-10 Batch 1: \n",
      "Loss = Train: 1.2321666479110718, Valid: 1.3284868001937866\n",
      "Accuracy = Train: 0.6000000238418579 Valid: 0.5369999408721924\n",
      "Epoch  6, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.8751884698867798, Valid: 1.2745740413665771\n",
      "Accuracy = Train: 0.7749999761581421 Valid: 0.5473999977111816\n",
      "Epoch  6, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.8381204009056091, Valid: 1.3100546598434448\n",
      "Accuracy = Train: 0.7000000476837158 Valid: 0.5505999326705933\n",
      "Epoch  6, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.9195364117622375, Valid: 1.2783557176589966\n",
      "Accuracy = Train: 0.75 Valid: 0.5523999333381653\n",
      "Epoch  6, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.9514493942260742, Valid: 1.2305126190185547\n",
      "Accuracy = Train: 0.7250000238418579 Valid: 0.5683999061584473\n",
      "Epoch  7, CIFAR-10 Batch 1: \n",
      "Loss = Train: 1.089797854423523, Valid: 1.2587213516235352\n",
      "Accuracy = Train: 0.6750000715255737 Valid: 0.5597999095916748\n",
      "Epoch  7, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.7948529720306396, Valid: 1.2715110778808594\n",
      "Accuracy = Train: 0.8250000476837158 Valid: 0.5595999360084534\n",
      "Epoch  7, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.7492040395736694, Valid: 1.252791404724121\n",
      "Accuracy = Train: 0.7000000476837158 Valid: 0.5583999156951904\n",
      "Epoch  7, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.8533321022987366, Valid: 1.2345026731491089\n",
      "Accuracy = Train: 0.6500000357627869 Valid: 0.5671999454498291\n",
      "Epoch  7, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.8297478556632996, Valid: 1.2069897651672363\n",
      "Accuracy = Train: 0.8500000238418579 Valid: 0.5767998695373535\n",
      "Epoch  8, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.9927554130554199, Valid: 1.2078392505645752\n",
      "Accuracy = Train: 0.7000000476837158 Valid: 0.5799999237060547\n",
      "Epoch  8, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.7499340176582336, Valid: 1.2576067447662354\n",
      "Accuracy = Train: 0.75 Valid: 0.5585999488830566\n",
      "Epoch  8, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.6583913564682007, Valid: 1.2484112977981567\n",
      "Accuracy = Train: 0.7750000357627869 Valid: 0.5751999616622925\n",
      "Epoch  8, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.7363069653511047, Valid: 1.1831084489822388\n",
      "Accuracy = Train: 0.7249999642372131 Valid: 0.587399959564209\n",
      "Epoch  8, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.730485737323761, Valid: 1.1522986888885498\n",
      "Accuracy = Train: 0.8500000238418579 Valid: 0.5959999561309814\n",
      "Epoch  9, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.8792577981948853, Valid: 1.1524230241775513\n",
      "Accuracy = Train: 0.7749999761581421 Valid: 0.5943998694419861\n",
      "Epoch  9, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.6571581363677979, Valid: 1.1506294012069702\n",
      "Accuracy = Train: 0.8500000238418579 Valid: 0.5909999012947083\n",
      "Epoch  9, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.6266652345657349, Valid: 1.1863586902618408\n",
      "Accuracy = Train: 0.7000000476837158 Valid: 0.5893999338150024\n",
      "Epoch  9, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.6744633913040161, Valid: 1.1502869129180908\n",
      "Accuracy = Train: 0.7749999761581421 Valid: 0.6029999256134033\n",
      "Epoch  9, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.6856393218040466, Valid: 1.129746437072754\n",
      "Accuracy = Train: 0.875 Valid: 0.6075999140739441\n",
      "Epoch 10, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.8524044156074524, Valid: 1.1391479969024658\n",
      "Accuracy = Train: 0.8250000476837158 Valid: 0.5997998714447021\n",
      "Epoch 10, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.6384682655334473, Valid: 1.1685271263122559\n",
      "Accuracy = Train: 0.8500000238418579 Valid: 0.5887998342514038\n",
      "Epoch 10, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.591561496257782, Valid: 1.1470903158187866\n",
      "Accuracy = Train: 0.7750000357627869 Valid: 0.6025999188423157\n",
      "Epoch 10, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.6564451456069946, Valid: 1.1601786613464355\n",
      "Accuracy = Train: 0.7749999761581421 Valid: 0.6009998917579651\n",
      "Epoch 10, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.644774317741394, Valid: 1.1016368865966797\n",
      "Accuracy = Train: 0.8250000476837158 Valid: 0.6181999444961548\n",
      "Epoch 11, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.8032357096672058, Valid: 1.1076388359069824\n",
      "Accuracy = Train: 0.7750000357627869 Valid: 0.6147999167442322\n",
      "Epoch 11, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.5451198220252991, Valid: 1.1034899950027466\n",
      "Accuracy = Train: 0.8750000596046448 Valid: 0.6139999032020569\n",
      "Epoch 11, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.605469822883606, Valid: 1.1528602838516235\n",
      "Accuracy = Train: 0.75 Valid: 0.5965999364852905\n",
      "Epoch 11, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.5784010291099548, Valid: 1.105438232421875\n",
      "Accuracy = Train: 0.800000011920929 Valid: 0.6171998977661133\n",
      "Epoch 11, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.5778390765190125, Valid: 1.0792791843414307\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6249998807907104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.7394480109214783, Valid: 1.0780600309371948\n",
      "Accuracy = Train: 0.800000011920929 Valid: 0.6233999133110046\n",
      "Epoch 12, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.5316076874732971, Valid: 1.1018285751342773\n",
      "Accuracy = Train: 0.8750000596046448 Valid: 0.6147999167442322\n",
      "Epoch 12, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.5454379320144653, Valid: 1.0977628231048584\n",
      "Accuracy = Train: 0.7749999761581421 Valid: 0.6165999174118042\n",
      "Epoch 12, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.631666362285614, Valid: 1.150433897972107\n",
      "Accuracy = Train: 0.7749999761581421 Valid: 0.6061999201774597\n",
      "Epoch 12, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.5187963247299194, Valid: 1.048606514930725\n",
      "Accuracy = Train: 0.9249999523162842 Valid: 0.637799859046936\n",
      "Epoch 13, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.7043607831001282, Valid: 1.0607781410217285\n",
      "Accuracy = Train: 0.800000011920929 Valid: 0.6323999166488647\n",
      "Epoch 13, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.4982413053512573, Valid: 1.1024723052978516\n",
      "Accuracy = Train: 0.8500000834465027 Valid: 0.6167999505996704\n",
      "Epoch 13, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.4770532250404358, Valid: 1.1220712661743164\n",
      "Accuracy = Train: 0.8250000476837158 Valid: 0.6135998964309692\n",
      "Epoch 13, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.571763813495636, Valid: 1.1175864934921265\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6195998787879944\n",
      "Epoch 13, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.5340111255645752, Valid: 1.0638593435287476\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6355998516082764\n",
      "Epoch 14, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.6539767384529114, Valid: 1.0618877410888672\n",
      "Accuracy = Train: 0.8250000476837158 Valid: 0.6311998963356018\n",
      "Epoch 14, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.48180854320526123, Valid: 1.192526936531067\n",
      "Accuracy = Train: 0.8500000834465027 Valid: 0.5823999643325806\n",
      "Epoch 14, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.4736243188381195, Valid: 1.0486464500427246\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6319998502731323\n",
      "Epoch 14, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.5245158076286316, Valid: 1.077794075012207\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6303999423980713\n",
      "Epoch 14, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.4990677833557129, Valid: 1.0873034000396729\n",
      "Accuracy = Train: 0.8500000238418579 Valid: 0.6267999410629272\n",
      "Epoch 15, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.5826444625854492, Valid: 1.0392104387283325\n",
      "Accuracy = Train: 0.875 Valid: 0.6379998922348022\n",
      "Epoch 15, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.39632678031921387, Valid: 1.105170726776123\n",
      "Accuracy = Train: 0.8750000596046448 Valid: 0.6147998571395874\n",
      "Epoch 15, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.3966805934906006, Valid: 1.0464203357696533\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6359999179840088\n",
      "Epoch 15, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.539746880531311, Valid: 1.1216174364089966\n",
      "Accuracy = Train: 0.824999988079071 Valid: 0.6205999255180359\n",
      "Epoch 15, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.4954281449317932, Valid: 1.0595366954803467\n",
      "Accuracy = Train: 0.9249999523162842 Valid: 0.6287999153137207\n",
      "Epoch 16, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.5526695251464844, Valid: 1.033623456954956\n",
      "Accuracy = Train: 0.800000011920929 Valid: 0.6449998617172241\n",
      "Epoch 16, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.35658928751945496, Valid: 1.0480971336364746\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6365998983383179\n",
      "Epoch 16, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.39513614773750305, Valid: 1.036600947380066\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6441998481750488\n",
      "Epoch 16, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.42578351497650146, Valid: 1.0627117156982422\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6377999186515808\n",
      "Epoch 16, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.47042515873908997, Valid: 1.0709997415542603\n",
      "Accuracy = Train: 0.8999999761581421 Valid: 0.6337999105453491\n",
      "Epoch 17, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.5441544055938721, Valid: 1.065293550491333\n",
      "Accuracy = Train: 0.8500000834465027 Valid: 0.6381998658180237\n",
      "Epoch 17, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.37636804580688477, Valid: 1.057399868965149\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6415998935699463\n",
      "Epoch 17, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.3908904492855072, Valid: 1.0638645887374878\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6409999132156372\n",
      "Epoch 17, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.45122191309928894, Valid: 1.0604667663574219\n",
      "Accuracy = Train: 0.875 Valid: 0.6435998678207397\n",
      "Epoch 17, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.4244258403778076, Valid: 1.0204682350158691\n",
      "Accuracy = Train: 0.9249999523162842 Valid: 0.6495998501777649\n",
      "Epoch 18, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.5528988838195801, Valid: 1.0291154384613037\n",
      "Accuracy = Train: 0.8500000834465027 Valid: 0.6459999084472656\n",
      "Epoch 18, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.3961392045021057, Valid: 1.0417087078094482\n",
      "Accuracy = Train: 0.8750000596046448 Valid: 0.6429998874664307\n",
      "Epoch 18, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.38305145502090454, Valid: 1.0452193021774292\n",
      "Accuracy = Train: 0.875 Valid: 0.6459999084472656\n",
      "Epoch 18, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.3702791929244995, Valid: 1.0459656715393066\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6409998536109924\n",
      "Epoch 18, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.4118063151836395, Valid: 1.0151309967041016\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6513998508453369\n",
      "Epoch 19, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.5008847117424011, Valid: 1.005348801612854\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6513999104499817\n",
      "Epoch 19, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.3513536751270294, Valid: 1.026320219039917\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6475999355316162\n",
      "Epoch 19, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.3516453504562378, Valid: 1.0341168642044067\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6535999178886414\n",
      "Epoch 19, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.397057443857193, Valid: 1.044790506362915\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6417999267578125\n",
      "Epoch 19, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.4494204521179199, Valid: 1.0641382932662964\n",
      "Accuracy = Train: 0.9249999523162842 Valid: 0.6403998732566833\n",
      "Epoch 20, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.49442097544670105, Valid: 1.0465083122253418\n",
      "Accuracy = Train: 0.8750000596046448 Valid: 0.639799952507019\n",
      "Epoch 20, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.315018892288208, Valid: 1.023869276046753\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6501999497413635\n",
      "Epoch 20, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.34424081444740295, Valid: 1.0470296144485474\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6431999206542969\n",
      "Epoch 20, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.3925948739051819, Valid: 1.0668718814849854\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6405999064445496\n",
      "Epoch 20, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.37908077239990234, Valid: 1.0192787647247314\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6525999307632446\n",
      "Epoch 21, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.4740952253341675, Valid: 1.0454415082931519\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6481998562812805\n",
      "Epoch 21, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.30015829205513, Valid: 1.0442801713943481\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.638999879360199\n",
      "Epoch 21, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.3205955922603607, Valid: 1.0664626359939575\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6423999071121216\n",
      "Epoch 21, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.3766884207725525, Valid: 1.0601091384887695\n",
      "Accuracy = Train: 0.8750000596046448 Valid: 0.6479999423027039\n",
      "Epoch 21, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.33991414308547974, Valid: 0.9922269582748413\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6585999131202698\n",
      "Epoch 22, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.3840641677379608, Valid: 1.0143887996673584\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6611998677253723\n",
      "Epoch 22, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.2758128046989441, Valid: 1.0140467882156372\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6525999307632446\n",
      "Epoch 22, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.3724382817745209, Valid: 1.134878158569336\n",
      "Accuracy = Train: 0.8750000596046448 Valid: 0.6253998875617981\n",
      "Epoch 22, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.319275438785553, Valid: 1.0089956521987915\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6563999056816101\n",
      "Epoch 22, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.3262072205543518, Valid: 1.002040982246399\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6543998718261719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.36730629205703735, Valid: 1.0278770923614502\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6497999429702759\n",
      "Epoch 23, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.2579675316810608, Valid: 1.0280221700668335\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6533998250961304\n",
      "Epoch 23, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.3395272493362427, Valid: 1.0670428276062012\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6497998833656311\n",
      "Epoch 23, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.26603901386260986, Valid: 0.9984036087989807\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6629998683929443\n",
      "Epoch 23, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.30211341381073, Valid: 0.9962748885154724\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6613998413085938\n",
      "Epoch 24, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.35063332319259644, Valid: 1.0383164882659912\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6505998969078064\n",
      "Epoch 24, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.22201132774353027, Valid: 1.026627540588379\n",
      "Accuracy = Train: 1.0 Valid: 0.653999924659729\n",
      "Epoch 24, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.33222001791000366, Valid: 1.1090142726898193\n",
      "Accuracy = Train: 0.875 Valid: 0.6283998489379883\n",
      "Epoch 24, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.28131547570228577, Valid: 1.007577657699585\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6643998622894287\n",
      "Epoch 24, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.3109252154827118, Valid: 1.0428709983825684\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6487998962402344\n",
      "Epoch 25, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.35534900426864624, Valid: 0.9901159405708313\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6611998677253723\n",
      "Epoch 25, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.2669358253479004, Valid: 1.0624511241912842\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6463998556137085\n",
      "Epoch 25, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.303212434053421, Valid: 1.0405020713806152\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6511999368667603\n",
      "Epoch 25, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.318711519241333, Valid: 1.0430653095245361\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6497998833656311\n",
      "Epoch 25, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.2849061191082001, Valid: 1.0330140590667725\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6543998718261719\n",
      "Epoch 26, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.3424634635448456, Valid: 1.0139575004577637\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6509998440742493\n",
      "Epoch 26, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.24596908688545227, Valid: 1.0439573526382446\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.653999924659729\n",
      "Epoch 26, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.23095302283763885, Valid: 1.0305668115615845\n",
      "Accuracy = Train: 1.0 Valid: 0.6577998995780945\n",
      "Epoch 26, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.24340607225894928, Valid: 1.0535861253738403\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6523998975753784\n",
      "Epoch 26, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.254117488861084, Valid: 1.0094999074935913\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6607999205589294\n",
      "Epoch 27, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.26671549677848816, Valid: 0.9906376600265503\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6669999361038208\n",
      "Epoch 27, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.28675374388694763, Valid: 1.1032966375350952\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6435999274253845\n",
      "Epoch 27, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.27278047800064087, Valid: 1.0281805992126465\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6547999382019043\n",
      "Epoch 27, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.19898319244384766, Valid: 0.9991523027420044\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.675399899482727\n",
      "Epoch 27, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.22954364120960236, Valid: 1.0126607418060303\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6587998867034912\n",
      "Epoch 28, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.2961145043373108, Valid: 1.0126756429672241\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6589998602867126\n",
      "Epoch 28, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.24382518231868744, Valid: 1.1597187519073486\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6313998699188232\n",
      "Epoch 28, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.2943175435066223, Valid: 1.022416353225708\n",
      "Accuracy = Train: 1.0 Valid: 0.6521998643875122\n",
      "Epoch 28, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.23663201928138733, Valid: 1.0319074392318726\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.665199875831604\n",
      "Epoch 28, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.22086992859840393, Valid: 0.9868144392967224\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6677998304367065\n",
      "Epoch 29, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.26464641094207764, Valid: 1.0471296310424805\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.650999903678894\n",
      "Epoch 29, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.19739066064357758, Valid: 1.0059459209442139\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6607998609542847\n",
      "Epoch 29, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.23838743567466736, Valid: 1.0505763292312622\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.646399974822998\n",
      "Epoch 29, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.23373937606811523, Valid: 1.0583570003509521\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.658599853515625\n",
      "Epoch 29, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.19538746774196625, Valid: 1.014119267463684\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6639999151229858\n",
      "Epoch 30, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.2552139461040497, Valid: 1.0027639865875244\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6647999286651611\n",
      "Epoch 30, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.20552217960357666, Valid: 1.0927550792694092\n",
      "Accuracy = Train: 1.0 Valid: 0.6417998671531677\n",
      "Epoch 30, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.26040124893188477, Valid: 1.0594637393951416\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6521998643875122\n",
      "Epoch 30, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.20243075489997864, Valid: 0.9848865270614624\n",
      "Accuracy = Train: 1.0 Valid: 0.6697998642921448\n",
      "Epoch 30, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.2130080759525299, Valid: 1.0381375551223755\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6589999198913574\n",
      "Epoch 31, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.22099608182907104, Valid: 1.0015912055969238\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6643998622894287\n",
      "Epoch 31, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.19731006026268005, Valid: 1.0836048126220703\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6429998874664307\n",
      "Epoch 31, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.19888824224472046, Valid: 1.0059758424758911\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6609998941421509\n",
      "Epoch 31, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.1988394856452942, Valid: 1.0204209089279175\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.655799925327301\n",
      "Epoch 31, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.15650831162929535, Valid: 0.9744983315467834\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6697999238967896\n",
      "Epoch 32, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.24096795916557312, Valid: 1.0035992860794067\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6733998656272888\n",
      "Epoch 32, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.13496068120002747, Valid: 1.0356758832931519\n",
      "Accuracy = Train: 1.0 Valid: 0.6617999076843262\n",
      "Epoch 32, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.16125595569610596, Valid: 0.9806733727455139\n",
      "Accuracy = Train: 1.0 Valid: 0.6773998737335205\n",
      "Epoch 32, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.21524597704410553, Valid: 1.0258190631866455\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6661998629570007\n",
      "Epoch 32, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.20568542182445526, Valid: 1.135504961013794\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6393998861312866\n",
      "Epoch 33, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.22685235738754272, Valid: 1.074631929397583\n",
      "Accuracy = Train: 0.9000000357627869 Valid: 0.6493998765945435\n",
      "Epoch 33, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.12406139075756073, Valid: 1.0739734172821045\n",
      "Accuracy = Train: 1.0 Valid: 0.6493998765945435\n",
      "Epoch 33, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.19325803220272064, Valid: 0.9846043586730957\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6735998392105103\n",
      "Epoch 33, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.16075016558170319, Valid: 1.0021491050720215\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6797999143600464\n",
      "Epoch 33, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.2589981257915497, Valid: 1.1499251127243042\n",
      "Accuracy = Train: 0.9249999523162842 Valid: 0.6353999376296997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.17774958908557892, Valid: 1.0823217630386353\n",
      "Accuracy = Train: 1.0 Valid: 0.6541999578475952\n",
      "Epoch 34, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.1146901473402977, Valid: 1.0242112874984741\n",
      "Accuracy = Train: 1.0 Valid: 0.6607998609542847\n",
      "Epoch 34, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.14983178675174713, Valid: 0.9653969407081604\n",
      "Accuracy = Train: 1.0 Valid: 0.6835999488830566\n",
      "Epoch 34, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.14872542023658752, Valid: 0.9816207885742188\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.679599940776825\n",
      "Epoch 34, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.13817670941352844, Valid: 1.0584560632705688\n",
      "Accuracy = Train: 1.0 Valid: 0.6549999117851257\n",
      "Epoch 35, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.2048003077507019, Valid: 1.0639421939849854\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6631999015808105\n",
      "Epoch 35, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.1163937896490097, Valid: 1.061671257019043\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6631999015808105\n",
      "Epoch 35, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.12249742448329926, Valid: 1.0023163557052612\n",
      "Accuracy = Train: 1.0 Valid: 0.6817998886108398\n",
      "Epoch 35, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.14411891996860504, Valid: 1.048361897468567\n",
      "Accuracy = Train: 1.0 Valid: 0.6569998860359192\n",
      "Epoch 35, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.20546652376651764, Valid: 1.119921088218689\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6327998638153076\n",
      "Epoch 36, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.1796664446592331, Valid: 1.02535080909729\n",
      "Accuracy = Train: 0.949999988079071 Valid: 0.6719998717308044\n",
      "Epoch 36, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.08742658793926239, Valid: 1.0645190477371216\n",
      "Accuracy = Train: 1.0 Valid: 0.6587998867034912\n",
      "Epoch 36, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.14912989735603333, Valid: 1.0079325437545776\n",
      "Accuracy = Train: 1.0 Valid: 0.6779998540878296\n",
      "Epoch 36, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.11761758476495743, Valid: 0.9792643189430237\n",
      "Accuracy = Train: 1.0 Valid: 0.6835998892784119\n",
      "Epoch 36, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.1034059077501297, Valid: 0.9901103973388672\n",
      "Accuracy = Train: 1.0 Valid: 0.6721998453140259\n",
      "Epoch 37, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.1386069804430008, Valid: 1.0139082670211792\n",
      "Accuracy = Train: 1.0 Valid: 0.6731998920440674\n",
      "Epoch 37, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.10366861522197723, Valid: 1.0639163255691528\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6643999218940735\n",
      "Epoch 37, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.14541053771972656, Valid: 1.026303768157959\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6667999029159546\n",
      "Epoch 37, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.12257444858551025, Valid: 1.036539912223816\n",
      "Accuracy = Train: 1.0 Valid: 0.6605998873710632\n",
      "Epoch 37, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.09326069056987762, Valid: 0.9740824103355408\n",
      "Accuracy = Train: 1.0 Valid: 0.6835998892784119\n",
      "Epoch 38, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.12784086167812347, Valid: 1.042712688446045\n",
      "Accuracy = Train: 1.0 Valid: 0.6681998372077942\n",
      "Epoch 38, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.0671326220035553, Valid: 1.0193835496902466\n",
      "Accuracy = Train: 1.0 Valid: 0.6771998405456543\n",
      "Epoch 38, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.09413550794124603, Valid: 0.9987400770187378\n",
      "Accuracy = Train: 1.0 Valid: 0.6827998757362366\n",
      "Epoch 38, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.06428233534097672, Valid: 0.9839742183685303\n",
      "Accuracy = Train: 1.0 Valid: 0.6809998750686646\n",
      "Epoch 38, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.10350783169269562, Valid: 1.0686216354370117\n",
      "Accuracy = Train: 1.0 Valid: 0.6611998677253723\n",
      "Epoch 39, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.15308071672916412, Valid: 1.0825281143188477\n",
      "Accuracy = Train: 0.925000011920929 Valid: 0.6521998643875122\n",
      "Epoch 39, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.06783945858478546, Valid: 1.0070431232452393\n",
      "Accuracy = Train: 1.0 Valid: 0.6769998669624329\n",
      "Epoch 39, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.1469230204820633, Valid: 1.0223735570907593\n",
      "Accuracy = Train: 0.9750000238418579 Valid: 0.6733999252319336\n",
      "Epoch 39, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.08042262494564056, Valid: 0.9728012084960938\n",
      "Accuracy = Train: 1.0 Valid: 0.6897998452186584\n",
      "Epoch 39, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.07235324382781982, Valid: 0.9841893911361694\n",
      "Accuracy = Train: 1.0 Valid: 0.6925998330116272\n",
      "Epoch 40, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.09273546934127808, Valid: 0.9597439169883728\n",
      "Accuracy = Train: 1.0 Valid: 0.6909998655319214\n",
      "Epoch 40, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.09551084041595459, Valid: 1.0121272802352905\n",
      "Accuracy = Train: 1.0 Valid: 0.6681998372077942\n",
      "Epoch 40, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.10600796341896057, Valid: 0.987400472164154\n",
      "Accuracy = Train: 1.0 Valid: 0.6891998052597046\n",
      "Epoch 40, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.08931483328342438, Valid: 1.018048644065857\n",
      "Accuracy = Train: 1.0 Valid: 0.6791999340057373\n",
      "Epoch 40, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.0798930674791336, Valid: 1.0458362102508545\n",
      "Accuracy = Train: 1.0 Valid: 0.67659991979599\n",
      "Epoch 41, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.08406874537467957, Valid: 1.0270442962646484\n",
      "Accuracy = Train: 1.0 Valid: 0.6757998466491699\n",
      "Epoch 41, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.08265214413404465, Valid: 1.0200214385986328\n",
      "Accuracy = Train: 1.0 Valid: 0.6799998879432678\n",
      "Epoch 41, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.07340173423290253, Valid: 1.0353970527648926\n",
      "Accuracy = Train: 1.0 Valid: 0.6751998662948608\n",
      "Epoch 41, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.05079607293009758, Valid: 1.0751371383666992\n",
      "Accuracy = Train: 1.0 Valid: 0.6679998636245728\n",
      "Epoch 41, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.074379101395607, Valid: 0.9884960651397705\n",
      "Accuracy = Train: 1.0 Valid: 0.6885998249053955\n",
      "Epoch 42, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.10196202993392944, Valid: 1.0673794746398926\n",
      "Accuracy = Train: 1.0 Valid: 0.6667999029159546\n",
      "Epoch 42, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.06525547802448273, Valid: 1.0174944400787354\n",
      "Accuracy = Train: 1.0 Valid: 0.6803998947143555\n",
      "Epoch 42, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.07563622295856476, Valid: 1.0604146718978882\n",
      "Accuracy = Train: 1.0 Valid: 0.6637998819351196\n",
      "Epoch 42, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.0637281984090805, Valid: 1.0464041233062744\n",
      "Accuracy = Train: 1.0 Valid: 0.6713998913764954\n",
      "Epoch 42, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.0684533566236496, Valid: 1.014582633972168\n",
      "Accuracy = Train: 1.0 Valid: 0.6869998574256897\n",
      "Epoch 43, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.07250353693962097, Valid: 1.0773193836212158\n",
      "Accuracy = Train: 1.0 Valid: 0.6751998662948608\n",
      "Epoch 43, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.07948339730501175, Valid: 1.0431462526321411\n",
      "Accuracy = Train: 1.0 Valid: 0.6701998710632324\n",
      "Epoch 43, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.07743337750434875, Valid: 1.0658366680145264\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6657998561859131\n",
      "Epoch 43, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.09054481983184814, Valid: 1.0747910737991333\n",
      "Accuracy = Train: 1.0 Valid: 0.6769999265670776\n",
      "Epoch 43, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.039364345371723175, Valid: 1.0176798105239868\n",
      "Accuracy = Train: 1.0 Valid: 0.6945999264717102\n",
      "Epoch 44, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.04877238720655441, Valid: 0.9984044432640076\n",
      "Accuracy = Train: 1.0 Valid: 0.6939998865127563\n",
      "Epoch 44, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.04524247720837593, Valid: 1.0540732145309448\n",
      "Accuracy = Train: 1.0 Valid: 0.6779998540878296\n",
      "Epoch 44, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.036448732018470764, Valid: 1.0196352005004883\n",
      "Accuracy = Train: 1.0 Valid: 0.6939998865127563\n",
      "Epoch 44, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.07865486294031143, Valid: 1.102852702140808\n",
      "Accuracy = Train: 0.9749999642372131 Valid: 0.6821998953819275\n",
      "Epoch 44, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.03940967097878456, Valid: 1.0203864574432373\n",
      "Accuracy = Train: 1.0 Valid: 0.685999870300293\n",
      "Epoch 45, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.056750424206256866, Valid: 1.0517990589141846\n",
      "Accuracy = Train: 1.0 Valid: 0.6853998303413391\n",
      "Epoch 45, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.04648832231760025, Valid: 1.0972670316696167\n",
      "Accuracy = Train: 1.0 Valid: 0.6719998717308044\n",
      "Epoch 45, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.030931968241930008, Valid: 1.0511362552642822\n",
      "Accuracy = Train: 1.0 Valid: 0.6851999163627625\n",
      "Epoch 45, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.03602306544780731, Valid: 1.0867164134979248\n",
      "Accuracy = Train: 1.0 Valid: 0.6775997877120972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.037165943533182144, Valid: 1.0379087924957275\n",
      "Accuracy = Train: 1.0 Valid: 0.6957999467849731\n",
      "Epoch 46, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.03608623147010803, Valid: 1.098768949508667\n",
      "Accuracy = Train: 1.0 Valid: 0.6761999130249023\n",
      "Epoch 46, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.04992076754570007, Valid: 1.0780953168869019\n",
      "Accuracy = Train: 1.0 Valid: 0.6835998296737671\n",
      "Epoch 46, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.04083847254514694, Valid: 1.0496954917907715\n",
      "Accuracy = Train: 1.0 Valid: 0.6879998445510864\n",
      "Epoch 46, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.026888955384492874, Valid: 1.0762656927108765\n",
      "Accuracy = Train: 1.0 Valid: 0.6897999048233032\n",
      "Epoch 46, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.03559815138578415, Valid: 1.0821210145950317\n",
      "Accuracy = Train: 1.0 Valid: 0.6867998838424683\n",
      "Epoch 47, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.06012666970491409, Valid: 1.1877236366271973\n",
      "Accuracy = Train: 1.0 Valid: 0.6685999035835266\n",
      "Epoch 47, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.04306242614984512, Valid: 1.064415454864502\n",
      "Accuracy = Train: 1.0 Valid: 0.6895998120307922\n",
      "Epoch 47, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.0413854643702507, Valid: 1.1352866888046265\n",
      "Accuracy = Train: 1.0 Valid: 0.6743998527526855\n",
      "Epoch 47, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.03275904059410095, Valid: 1.130081057548523\n",
      "Accuracy = Train: 1.0 Valid: 0.6741998791694641\n",
      "Epoch 47, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.027277514338493347, Valid: 1.0730971097946167\n",
      "Accuracy = Train: 1.0 Valid: 0.6965998411178589\n",
      "Epoch 48, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.026073120534420013, Valid: 1.0883883237838745\n",
      "Accuracy = Train: 1.0 Valid: 0.6881999373435974\n",
      "Epoch 48, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.03640923276543617, Valid: 1.098611831665039\n",
      "Accuracy = Train: 1.0 Valid: 0.6839998960494995\n",
      "Epoch 48, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.04455442726612091, Valid: 1.1175916194915771\n",
      "Accuracy = Train: 1.0 Valid: 0.6821998953819275\n",
      "Epoch 48, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.027207186445593834, Valid: 1.0845224857330322\n",
      "Accuracy = Train: 1.0 Valid: 0.6879998445510864\n",
      "Epoch 48, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.03778253123164177, Valid: 1.1146206855773926\n",
      "Accuracy = Train: 1.0 Valid: 0.6897998452186584\n",
      "Epoch 49, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.015149258077144623, Valid: 1.0513989925384521\n",
      "Accuracy = Train: 1.0 Valid: 0.697999894618988\n",
      "Epoch 49, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.018289020285010338, Valid: 1.0819400548934937\n",
      "Accuracy = Train: 1.0 Valid: 0.6887999176979065\n",
      "Epoch 49, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.017479002475738525, Valid: 1.0894256830215454\n",
      "Accuracy = Train: 1.0 Valid: 0.693199872970581\n",
      "Epoch 49, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.031148051843047142, Valid: 1.1438710689544678\n",
      "Accuracy = Train: 1.0 Valid: 0.6859998106956482\n",
      "Epoch 49, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.022999484091997147, Valid: 1.108596920967102\n",
      "Accuracy = Train: 1.0 Valid: 0.6909998655319214\n",
      "Epoch 50, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.015250517055392265, Valid: 1.135241150856018\n",
      "Accuracy = Train: 1.0 Valid: 0.6903998851776123\n",
      "Epoch 50, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.011638384312391281, Valid: 1.0888521671295166\n",
      "Accuracy = Train: 1.0 Valid: 0.6935998797416687\n",
      "Epoch 50, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.03765953704714775, Valid: 1.168388843536377\n",
      "Accuracy = Train: 1.0 Valid: 0.6761998534202576\n",
      "Epoch 50, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.013775120489299297, Valid: 1.1008543968200684\n",
      "Accuracy = Train: 1.0 Valid: 0.694199800491333\n",
      "Epoch 50, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.0093169454485178, Valid: 1.1032888889312744\n",
      "Accuracy = Train: 1.0 Valid: 0.6959998607635498\n",
      "Epoch 51, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.017109517008066177, Valid: 1.1425093412399292\n",
      "Accuracy = Train: 1.0 Valid: 0.6827998757362366\n",
      "Epoch 51, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.017261479049921036, Valid: 1.1575840711593628\n",
      "Accuracy = Train: 1.0 Valid: 0.6825998425483704\n",
      "Epoch 51, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.020592890679836273, Valid: 1.1407465934753418\n",
      "Accuracy = Train: 1.0 Valid: 0.6951998472213745\n",
      "Epoch 51, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.014340244233608246, Valid: 1.1168231964111328\n",
      "Accuracy = Train: 1.0 Valid: 0.6875998973846436\n",
      "Epoch 51, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.014912457205355167, Valid: 1.1612519025802612\n",
      "Accuracy = Train: 1.0 Valid: 0.6911998987197876\n",
      "Epoch 52, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.015261778607964516, Valid: 1.0817989110946655\n",
      "Accuracy = Train: 1.0 Valid: 0.6985998153686523\n",
      "Epoch 52, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.010252503678202629, Valid: 1.1405670642852783\n",
      "Accuracy = Train: 1.0 Valid: 0.6967998743057251\n",
      "Epoch 52, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.0265812911093235, Valid: 1.2565540075302124\n",
      "Accuracy = Train: 1.0 Valid: 0.6749998331069946\n",
      "Epoch 52, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.008315932005643845, Valid: 1.166944146156311\n",
      "Accuracy = Train: 1.0 Valid: 0.6915998458862305\n",
      "Epoch 52, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.015258347615599632, Valid: 1.2108943462371826\n",
      "Accuracy = Train: 1.0 Valid: 0.6903997659683228\n",
      "Epoch 53, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.014306086115539074, Valid: 1.164963722229004\n",
      "Accuracy = Train: 1.0 Valid: 0.6881998777389526\n",
      "Epoch 53, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.007847223430871964, Valid: 1.1495566368103027\n",
      "Accuracy = Train: 1.0 Valid: 0.6971998810768127\n",
      "Epoch 53, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.00822506844997406, Valid: 1.1591382026672363\n",
      "Accuracy = Train: 1.0 Valid: 0.6915999054908752\n",
      "Epoch 53, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.007817302830517292, Valid: 1.1742926836013794\n",
      "Accuracy = Train: 1.0 Valid: 0.6955997943878174\n",
      "Epoch 53, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.013324642553925514, Valid: 1.1685760021209717\n",
      "Accuracy = Train: 1.0 Valid: 0.6979998350143433\n",
      "Epoch 54, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.009019339457154274, Valid: 1.1974091529846191\n",
      "Accuracy = Train: 1.0 Valid: 0.691199779510498\n",
      "Epoch 54, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.005837076809257269, Valid: 1.1802531480789185\n",
      "Accuracy = Train: 1.0 Valid: 0.6891998648643494\n",
      "Epoch 54, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.010139092803001404, Valid: 1.172899842262268\n",
      "Accuracy = Train: 1.0 Valid: 0.6941998600959778\n",
      "Epoch 54, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.0046569667756557465, Valid: 1.1720266342163086\n",
      "Accuracy = Train: 1.0 Valid: 0.6911998987197876\n",
      "Epoch 54, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.008874050341546535, Valid: 1.235952377319336\n",
      "Accuracy = Train: 1.0 Valid: 0.6897998452186584\n",
      "Epoch 55, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.007022879086434841, Valid: 1.2248616218566895\n",
      "Accuracy = Train: 1.0 Valid: 0.6875998973846436\n",
      "Epoch 55, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.004950868431478739, Valid: 1.224271535873413\n",
      "Accuracy = Train: 1.0 Valid: 0.6967998743057251\n",
      "Epoch 55, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.010149277746677399, Valid: 1.2213743925094604\n",
      "Accuracy = Train: 1.0 Valid: 0.6843998432159424\n",
      "Epoch 55, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.005974772851914167, Valid: 1.2333012819290161\n",
      "Accuracy = Train: 1.0 Valid: 0.6891998648643494\n",
      "Epoch 55, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.008856851607561111, Valid: 1.2324941158294678\n",
      "Accuracy = Train: 1.0 Valid: 0.6905998587608337\n",
      "Epoch 56, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.010447639971971512, Valid: 1.2503936290740967\n",
      "Accuracy = Train: 1.0 Valid: 0.6873999238014221\n",
      "Epoch 56, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.005839614197611809, Valid: 1.2186024188995361\n",
      "Accuracy = Train: 1.0 Valid: 0.6927998661994934\n",
      "Epoch 56, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.007240563631057739, Valid: 1.1939653158187866\n",
      "Accuracy = Train: 1.0 Valid: 0.6911998987197876\n",
      "Epoch 56, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.005326441023498774, Valid: 1.217782974243164\n",
      "Accuracy = Train: 1.0 Valid: 0.6909999251365662\n",
      "Epoch 56, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.009368259459733963, Valid: 1.3657315969467163\n",
      "Accuracy = Train: 1.0 Valid: 0.6707998514175415\n",
      "Epoch 57, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.007087969221174717, Valid: 1.2918745279312134\n",
      "Accuracy = Train: 1.0 Valid: 0.6791998744010925\n",
      "Epoch 57, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.009726651944220066, Valid: 1.3227612972259521\n",
      "Accuracy = Train: 1.0 Valid: 0.6831998229026794\n",
      "Epoch 57, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.008085735142230988, Valid: 1.331690788269043\n",
      "Accuracy = Train: 1.0 Valid: 0.6759998798370361\n",
      "Epoch 57, CIFAR-10 Batch 4: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = Train: 0.005347368773072958, Valid: 1.273884654045105\n",
      "Accuracy = Train: 1.0 Valid: 0.6863999366760254\n",
      "Epoch 57, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.00418979674577713, Valid: 1.346576452255249\n",
      "Accuracy = Train: 1.0 Valid: 0.6803998351097107\n",
      "Epoch 58, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.008813058026134968, Valid: 1.313467025756836\n",
      "Accuracy = Train: 1.0 Valid: 0.6827998757362366\n",
      "Epoch 58, CIFAR-10 Batch 2: \n",
      "Loss = Train: 0.006642468273639679, Valid: 1.3365309238433838\n",
      "Accuracy = Train: 1.0 Valid: 0.6831998229026794\n",
      "Epoch 58, CIFAR-10 Batch 3: \n",
      "Loss = Train: 0.0038356981240212917, Valid: 1.3379743099212646\n",
      "Accuracy = Train: 1.0 Valid: 0.6797999143600464\n",
      "Epoch 58, CIFAR-10 Batch 4: \n",
      "Loss = Train: 0.005457872524857521, Valid: 1.3283274173736572\n",
      "Accuracy = Train: 1.0 Valid: 0.679399847984314\n",
      "Epoch 58, CIFAR-10 Batch 5: \n",
      "Loss = Train: 0.012619979679584503, Valid: 1.3217226266860962\n",
      "Accuracy = Train: 1.0 Valid: 0.6825998425483704\n",
      "Epoch 59, CIFAR-10 Batch 1: \n",
      "Loss = Train: 0.005323669873178005, Valid: 1.3470118045806885\n",
      "Accuracy = Train: 1.0 Valid: 0.6773998141288757\n",
      "Epoch 59, CIFAR-10 Batch 2: \n",
      "Loss = Train: 358.4122619628906, Valid: 436.23321533203125\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.07579999417066574\n",
      "Epoch 59, CIFAR-10 Batch 3: \n",
      "Loss = Train: 30.9791316986084, Valid: 31.23480987548828\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 59, CIFAR-10 Batch 4: \n",
      "Loss = Train: 29.000972747802734, Valid: 29.733009338378906\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 59, CIFAR-10 Batch 5: \n",
      "Loss = Train: 28.259851455688477, Valid: 27.848554611206055\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 60, CIFAR-10 Batch 1: \n",
      "Loss = Train: 26.31982421875, Valid: 26.056922912597656\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 60, CIFAR-10 Batch 2: \n",
      "Loss = Train: 23.090370178222656, Valid: 24.34541893005371\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 60, CIFAR-10 Batch 3: \n",
      "Loss = Train: 22.45755386352539, Valid: 22.740642547607422\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 60, CIFAR-10 Batch 4: \n",
      "Loss = Train: 20.51645278930664, Valid: 21.201873779296875\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 60, CIFAR-10 Batch 5: \n",
      "Loss = Train: 20.369199752807617, Valid: 19.756906509399414\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 61, CIFAR-10 Batch 1: \n",
      "Loss = Train: 18.431455612182617, Valid: 18.40567398071289\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 61, CIFAR-10 Batch 2: \n",
      "Loss = Train: 16.121692657470703, Valid: 17.17333984375\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 61, CIFAR-10 Batch 3: \n",
      "Loss = Train: 15.842391967773438, Valid: 16.134658813476562\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 61, CIFAR-10 Batch 4: \n",
      "Loss = Train: 14.66905689239502, Valid: 15.281269073486328\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 61, CIFAR-10 Batch 5: \n",
      "Loss = Train: 15.316579818725586, Valid: 14.565719604492188\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 62, CIFAR-10 Batch 1: \n",
      "Loss = Train: 13.815293312072754, Valid: 13.912496566772461\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 62, CIFAR-10 Batch 2: \n",
      "Loss = Train: 12.422525405883789, Valid: 13.296172142028809\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 62, CIFAR-10 Batch 3: \n",
      "Loss = Train: 12.487186431884766, Valid: 12.728782653808594\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 62, CIFAR-10 Batch 4: \n",
      "Loss = Train: 11.806082725524902, Valid: 12.197569847106934\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 62, CIFAR-10 Batch 5: \n",
      "Loss = Train: 12.50174617767334, Valid: 11.71474838256836\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 63, CIFAR-10 Batch 1: \n",
      "Loss = Train: 11.163877487182617, Valid: 11.272197723388672\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 63, CIFAR-10 Batch 2: \n",
      "Loss = Train: 10.135697364807129, Valid: 10.854642868041992\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 63, CIFAR-10 Batch 3: \n",
      "Loss = Train: 10.270000457763672, Valid: 10.455155372619629\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 63, CIFAR-10 Batch 4: \n",
      "Loss = Train: 9.76956558227539, Valid: 10.053390502929688\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 63, CIFAR-10 Batch 5: \n",
      "Loss = Train: 10.333024978637695, Valid: 9.664551734924316\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 64, CIFAR-10 Batch 1: \n",
      "Loss = Train: 9.21490478515625, Valid: 9.284403800964355\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 64, CIFAR-10 Batch 2: \n",
      "Loss = Train: 8.323457717895508, Valid: 8.915372848510742\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 64, CIFAR-10 Batch 3: \n",
      "Loss = Train: 8.418534278869629, Valid: 8.55611515045166\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 64, CIFAR-10 Batch 4: \n",
      "Loss = Train: 7.963535308837891, Valid: 8.19707202911377\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 64, CIFAR-10 Batch 5: \n",
      "Loss = Train: 8.375371932983398, Valid: 7.850279331207275\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 65, CIFAR-10 Batch 1: \n",
      "Loss = Train: 7.486245155334473, Valid: 7.51361608505249\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 65, CIFAR-10 Batch 2: \n",
      "Loss = Train: 6.706752777099609, Valid: 7.185895919799805\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 65, CIFAR-10 Batch 3: \n",
      "Loss = Train: 6.7750244140625, Valid: 6.870283603668213\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 65, CIFAR-10 Batch 4: \n",
      "Loss = Train: 6.364048957824707, Valid: 6.555423736572266\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 65, CIFAR-10 Batch 5: \n",
      "Loss = Train: 6.649506568908691, Valid: 6.252642631530762\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 66, CIFAR-10 Batch 1: \n",
      "Loss = Train: 5.971526145935059, Valid: 5.961787700653076\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 66, CIFAR-10 Batch 2: \n",
      "Loss = Train: 5.301093578338623, Valid: 5.680497646331787\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 66, CIFAR-10 Batch 3: \n",
      "Loss = Train: 5.354582786560059, Valid: 5.412298202514648\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 66, CIFAR-10 Batch 4: \n",
      "Loss = Train: 4.992933750152588, Valid: 5.148118019104004\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10300000011920929\n",
      "Epoch 66, CIFAR-10 Batch 5: \n",
      "Loss = Train: 5.186095237731934, Valid: 4.899349689483643\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 67, CIFAR-10 Batch 1: \n",
      "Loss = Train: 4.702716827392578, Valid: 4.663003444671631\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 67, CIFAR-10 Batch 2: \n",
      "Loss = Train: 4.152976036071777, Valid: 4.443521499633789\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 67, CIFAR-10 Batch 3: \n",
      "Loss = Train: 4.214312553405762, Valid: 4.237643241882324\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 67, CIFAR-10 Batch 4: \n",
      "Loss = Train: 3.916173219680786, Valid: 4.042175769805908\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 67, CIFAR-10 Batch 5: \n",
      "Loss = Train: 4.060412883758545, Valid: 3.863645315170288\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 68, CIFAR-10 Batch 1: \n",
      "Loss = Train: 3.7573049068450928, Valid: 3.6994495391845703\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 68, CIFAR-10 Batch 2: \n",
      "Loss = Train: 3.3435182571411133, Valid: 3.5485944747924805\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 68, CIFAR-10 Batch 3: \n",
      "Loss = Train: 3.4251246452331543, Valid: 3.414119243621826\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 68, CIFAR-10 Batch 4: \n",
      "Loss = Train: 3.185822010040283, Valid: 3.2888128757476807\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 68, CIFAR-10 Batch 5: \n",
      "Loss = Train: 3.3048789501190186, Valid: 3.1774742603302\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, CIFAR-10 Batch 1: \n",
      "Loss = Train: 3.1392228603363037, Valid: 3.077713966369629\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 69, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.8621864318847656, Valid: 2.987165927886963\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 69, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.9457645416259766, Valid: 2.906965494155884\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 69, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.7521095275878906, Valid: 2.832805633544922\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 69, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.844038963317871, Valid: 2.766559600830078\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 70, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.763651132583618, Valid: 2.708523988723755\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 70, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.5914859771728516, Valid: 2.6561315059661865\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 70, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.6599979400634766, Valid: 2.6096386909484863\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 70, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.510000705718994, Valid: 2.567387580871582\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 70, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.5729448795318604, Valid: 2.529975414276123\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 71, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.542156934738159, Valid: 2.4979400634765625\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 71, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.4411332607269287, Valid: 2.4698405265808105\n",
      "Accuracy = Train: 0.125 Valid: 0.10300000011920929\n",
      "Epoch 71, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.491990566253662, Valid: 2.445420503616333\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 71, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3855209350585938, Valid: 2.4232826232910156\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 71, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.4244117736816406, Valid: 2.403947353363037\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 72, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.4205474853515625, Valid: 2.388211488723755\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 72, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3621761798858643, Valid: 2.3744022846221924\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 72, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.3965823650360107, Valid: 2.362752914428711\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 72, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3281071186065674, Valid: 2.352374792098999\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 72, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3512160778045654, Valid: 2.3437182903289795\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 73, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.358290910720825, Valid: 2.3367221355438232\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 73, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.32379412651062, Valid: 2.330747365951538\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 73, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.345480442047119, Valid: 2.3257131576538086\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 73, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.305575370788574, Valid: 2.3212053775787354\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 73, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.318446636199951, Valid: 2.317772388458252\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 74, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3284928798675537, Valid: 2.3150603771209717\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 74, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.306591272354126, Valid: 2.312685966491699\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 74, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.3196327686309814, Valid: 2.310758113861084\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 74, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2988364696502686, Valid: 2.3091211318969727\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 74, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.30584454536438, Valid: 2.307889938354492\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 75, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.314873456954956, Valid: 2.3069353103637695\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 75, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3002066612243652, Valid: 2.3060126304626465\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 75, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.307581663131714, Valid: 2.3053460121154785\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 75, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2977819442749023, Valid: 2.3048348426818848\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 75, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3015706539154053, Valid: 2.304452657699585\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 76, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3087611198425293, Valid: 2.3041322231292725\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 76, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.298504114151001, Valid: 2.303739547729492\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 76, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.3024816513061523, Valid: 2.3035154342651367\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 76, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.298491954803467, Valid: 2.3034117221832275\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 76, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3006327152252197, Valid: 2.303335189819336\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 77, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3060340881347656, Valid: 2.303222894668579\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 77, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2985501289367676, Valid: 2.302992105484009\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 77, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.300560712814331, Valid: 2.302917957305908\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10300000011920929\n",
      "Epoch 77, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.299206256866455, Valid: 2.30301833152771\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 77, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3007466793060303, Valid: 2.303039789199829\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 78, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3046531677246094, Valid: 2.3029820919036865\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 78, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.299103021621704, Valid: 2.3027760982513428\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 78, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.299835443496704, Valid: 2.302738666534424\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 78, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2998390197753906, Valid: 2.302879810333252\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 78, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301241397857666, Valid: 2.3029305934906006\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 79, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303771495819092, Valid: 2.3028783798217773\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 79, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.300194025039673, Valid: 2.302687644958496\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 79, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2997689247131348, Valid: 2.302663564682007\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 79, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3005480766296387, Valid: 2.302842855453491\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 79, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3015692234039307, Valid: 2.302936315536499\n",
      "Accuracy = Train: 0.125 Valid: 0.10300000011920929\n",
      "Epoch 80, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3033556938171387, Valid: 2.3028972148895264\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.300553798675537, Valid: 2.302708864212036\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 80, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.299652576446533, Valid: 2.302680730819702\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 80, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3004379272460938, Valid: 2.3028793334960938\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 80, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3016819953918457, Valid: 2.3029632568359375\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 81, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303295612335205, Valid: 2.3029282093048096\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10299999266862869\n",
      "Epoch 81, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3010706901550293, Valid: 2.3027093410491943\n",
      "Accuracy = Train: 0.125 Valid: 0.10299999266862869\n",
      "Epoch 81, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.299809694290161, Valid: 2.30267333984375\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10299999266862869\n",
      "Epoch 81, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3004398345947266, Valid: 2.3028907775878906\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 81, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301767349243164, Valid: 2.302978754043579\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 82, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303018093109131, Valid: 2.30291748046875\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 82, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.30153226852417, Valid: 2.3026912212371826\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999064207077\n",
      "Epoch 82, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2997994422912598, Valid: 2.302664041519165\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 82, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3004941940307617, Valid: 2.302908420562744\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 82, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3018951416015625, Valid: 2.302995204925537\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 83, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.302919387817383, Valid: 2.302927255630493\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 83, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3015284538269043, Valid: 2.302698850631714\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999064207077\n",
      "Epoch 83, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2994887828826904, Valid: 2.3026766777038574\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 83, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300504207611084, Valid: 2.302935838699341\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 83, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3020100593566895, Valid: 2.303039073944092\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 84, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3028531074523926, Valid: 2.3029561042785645\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 84, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.301516532897949, Valid: 2.302696466445923\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999064207077\n",
      "Epoch 84, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.299351930618286, Valid: 2.302659511566162\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 84, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300473213195801, Valid: 2.3029394149780273\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 84, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301828622817993, Valid: 2.303046941757202\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 85, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3029046058654785, Valid: 2.3029465675354004\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 85, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3016114234924316, Valid: 2.302677869796753\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999809265137\n",
      "Epoch 85, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.299128293991089, Valid: 2.302669048309326\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 85, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300417184829712, Valid: 2.302978038787842\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 85, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3018476963043213, Valid: 2.3030686378479004\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 86, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.302943468093872, Valid: 2.302948236465454\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 86, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.302389621734619, Valid: 2.302642345428467\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999064207077\n",
      "Epoch 86, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2994654178619385, Valid: 2.3026371002197266\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999809265137\n",
      "Epoch 86, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3004236221313477, Valid: 2.3029894828796387\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 86, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301637649536133, Valid: 2.3030848503112793\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 87, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.30298113822937, Valid: 2.3029539585113525\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 87, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3022518157958984, Valid: 2.302624464035034\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999809265137\n",
      "Epoch 87, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2990403175354004, Valid: 2.302626609802246\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 87, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3005597591400146, Valid: 2.302994728088379\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 87, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301708459854126, Valid: 2.303114891052246\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 88, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303051233291626, Valid: 2.3029706478118896\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 88, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.302269458770752, Valid: 2.3026270866394043\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999064207077\n",
      "Epoch 88, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.298623561859131, Valid: 2.3026375770568848\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 88, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300273895263672, Valid: 2.303067445755005\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 88, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301617383956909, Valid: 2.303159236907959\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 89, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3030147552490234, Valid: 2.302987813949585\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 89, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3024542331695557, Valid: 2.3026015758514404\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 89, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2986202239990234, Valid: 2.302631378173828\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 89, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300166606903076, Valid: 2.3030588626861572\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 89, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3012237548828125, Valid: 2.3031654357910156\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 90, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303152084350586, Valid: 2.3029897212982178\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 90, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3025102615356445, Valid: 2.3025949001312256\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999064207077\n",
      "Epoch 90, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2982282638549805, Valid: 2.302642822265625\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 90, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2997517585754395, Valid: 2.3031420707702637\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 90, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.30122447013855, Valid: 2.3032326698303223\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 91, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3032102584838867, Valid: 2.3029816150665283\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 91, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.30261492729187, Valid: 2.3025615215301514\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 91, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2976152896881104, Valid: 2.3026461601257324\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2999823093414307, Valid: 2.3031630516052246\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 91, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301104784011841, Valid: 2.3032355308532715\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 92, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3032636642456055, Valid: 2.3029708862304688\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 92, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3027024269104004, Valid: 2.30257248878479\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 92, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.297703981399536, Valid: 2.3026461601257324\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 92, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2997069358825684, Valid: 2.3031821250915527\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 92, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3009438514709473, Valid: 2.3032779693603516\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 93, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3033313751220703, Valid: 2.3029987812042236\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 93, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.303057909011841, Valid: 2.3025312423706055\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 93, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2973310947418213, Valid: 2.3026554584503174\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 93, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2993216514587402, Valid: 2.3032541275024414\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 93, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3007731437683105, Valid: 2.3033080101013184\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 94, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303440570831299, Valid: 2.3029544353485107\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 94, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3032710552215576, Valid: 2.3025121688842773\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 94, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.296863317489624, Valid: 2.302670955657959\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 94, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.299121379852295, Valid: 2.303304672241211\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 94, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300656318664551, Valid: 2.3033337593078613\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 95, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3034777641296387, Valid: 2.302953004837036\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 95, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3034260272979736, Valid: 2.302499294281006\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 95, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.296445608139038, Valid: 2.3026983737945557\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 95, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2989730834960938, Valid: 2.303347110748291\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 95, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300499677658081, Valid: 2.3033430576324463\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 96, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3035616874694824, Valid: 2.3029468059539795\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 96, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.30373477935791, Valid: 2.302461624145508\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 96, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.296729564666748, Valid: 2.3026437759399414\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 96, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.298532724380493, Valid: 2.3033628463745117\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 96, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300161600112915, Valid: 2.3033318519592285\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 97, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3037335872650146, Valid: 2.3029158115386963\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 97, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.304152011871338, Valid: 2.302473545074463\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 97, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2960243225097656, Valid: 2.302767515182495\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 97, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2980799674987793, Valid: 2.303464651107788\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 97, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300062894821167, Valid: 2.3033974170684814\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 98, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3036375045776367, Valid: 2.302917957305908\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 98, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3039376735687256, Valid: 2.3024654388427734\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 98, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.294797420501709, Valid: 2.302809000015259\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 98, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2979257106781006, Valid: 2.303557872772217\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 98, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299708127975464, Valid: 2.303455114364624\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 99, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3037242889404297, Valid: 2.302913188934326\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 99, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.304218053817749, Valid: 2.3024818897247314\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 99, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.294373035430908, Valid: 2.3028790950775146\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 99, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2978131771087646, Valid: 2.3035762310028076\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 99, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299866199493408, Valid: 2.303433656692505\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 100, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3038883209228516, Valid: 2.302891731262207\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 100, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3044962882995605, Valid: 2.3024888038635254\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 100, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2939462661743164, Valid: 2.302945613861084\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 100, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2973580360412598, Valid: 2.3036160469055176\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 100, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299670457839966, Valid: 2.303408145904541\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 101, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.304018020629883, Valid: 2.3028671741485596\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 101, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3047266006469727, Valid: 2.302509307861328\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 101, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2931299209594727, Valid: 2.3030052185058594\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 101, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2974441051483154, Valid: 2.3036136627197266\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 101, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299689769744873, Valid: 2.303464651107788\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 102, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303938150405884, Valid: 2.302882671356201\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 102, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.30478572845459, Valid: 2.3025765419006348\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 102, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2928006649017334, Valid: 2.303079605102539\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 102, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2972686290740967, Valid: 2.303668260574341\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299429416656494, Valid: 2.3034393787384033\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 103, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303863763809204, Valid: 2.302842140197754\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 103, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.305044174194336, Valid: 2.302583694458008\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 103, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2923405170440674, Valid: 2.3031723499298096\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 103, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2972850799560547, Valid: 2.3036632537841797\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 103, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.29935622215271, Valid: 2.30346417427063\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 104, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3040738105773926, Valid: 2.3028438091278076\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 104, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3052186965942383, Valid: 2.302598476409912\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 104, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2919564247131348, Valid: 2.303253173828125\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 104, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.297414779663086, Valid: 2.30369234085083\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 104, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2993342876434326, Valid: 2.3034796714782715\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 105, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.304189920425415, Valid: 2.3028316497802734\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 105, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3053414821624756, Valid: 2.302668809890747\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.10679998993873596\n",
      "Epoch 105, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2914085388183594, Valid: 2.3033318519592285\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 105, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.297545909881592, Valid: 2.3036632537841797\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 105, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2991652488708496, Valid: 2.3034918308258057\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 106, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3043224811553955, Valid: 2.302823543548584\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 106, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3062376976013184, Valid: 2.3027491569519043\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.10679998993873596\n",
      "Epoch 106, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.290830612182617, Valid: 2.303506374359131\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 106, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2981858253479004, Valid: 2.303612470626831\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 106, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2992589473724365, Valid: 2.3035378456115723\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 107, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3043789863586426, Valid: 2.302868604660034\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 107, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.305854558944702, Valid: 2.302795648574829\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.10679998993873596\n",
      "Epoch 107, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2907185554504395, Valid: 2.3035523891448975\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 107, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.298053026199341, Valid: 2.3036375045776367\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 107, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2992136478424072, Valid: 2.3036155700683594\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 108, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303713798522949, Valid: 2.30279541015625\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999981045723\n",
      "Epoch 108, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.305173873901367, Valid: 2.302919387817383\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.10679998993873596\n",
      "Epoch 108, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2907209396362305, Valid: 2.303662061691284\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 108, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.298344850540161, Valid: 2.3036484718322754\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 108, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299269199371338, Valid: 2.3037607669830322\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 109, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.304400682449341, Valid: 2.3028080463409424\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 109, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.305666923522949, Valid: 2.3029894828796387\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.10679998993873596\n",
      "Epoch 109, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.290139675140381, Valid: 2.303844928741455\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 109, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2990710735321045, Valid: 2.303591012954712\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 109, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2992632389068604, Valid: 2.3037946224212646\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 110, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3044207096099854, Valid: 2.302765369415283\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999981045723\n",
      "Epoch 110, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3055551052093506, Valid: 2.3031158447265625\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 110, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.290221691131592, Valid: 2.3039145469665527\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 110, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2994577884674072, Valid: 2.303649425506592\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 110, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2994673252105713, Valid: 2.3039140701293945\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 111, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3042173385620117, Valid: 2.302741050720215\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999981045723\n",
      "Epoch 111, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3046956062316895, Valid: 2.3031773567199707\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 111, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2903928756713867, Valid: 2.3041319847106934\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 111, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.299994945526123, Valid: 2.303659200668335\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 111, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2990894317626953, Valid: 2.304004430770874\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 112, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303950786590576, Valid: 2.302722454071045\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 112, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3052914142608643, Valid: 2.3033394813537598\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 112, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.290288209915161, Valid: 2.3042643070220947\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 112, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300593852996826, Valid: 2.303704261779785\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 112, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299156904220581, Valid: 2.304144859313965\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 113, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3036279678344727, Valid: 2.302670955657959\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 113, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3052620887756348, Valid: 2.3035006523132324\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 113, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2904560565948486, Valid: 2.3044934272766113\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 113, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.301238536834717, Valid: 2.3036913871765137\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 113, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299257755279541, Valid: 2.3042538166046143\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.303241491317749, Valid: 2.30263090133667\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999981045723\n",
      "Epoch 114, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3047678470611572, Valid: 2.303602695465088\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 114, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.29073166847229, Valid: 2.304804563522339\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 114, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.301680564880371, Valid: 2.303823471069336\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 114, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299184560775757, Valid: 2.3043718338012695\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 115, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3026504516601562, Valid: 2.302584171295166\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 115, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3041465282440186, Valid: 2.3037116527557373\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 115, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2909834384918213, Valid: 2.305138349533081\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 115, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3020472526550293, Valid: 2.3038747310638428\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 115, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2992193698883057, Valid: 2.3045597076416016\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 116, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3020808696746826, Valid: 2.30256724357605\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 116, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.303744077682495, Valid: 2.30379056930542\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 116, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2912545204162598, Valid: 2.3055672645568848\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 116, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.302028179168701, Valid: 2.30399751663208\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 116, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2991623878479004, Valid: 2.304729461669922\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 117, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3014514446258545, Valid: 2.302584171295166\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 117, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3031201362609863, Valid: 2.303792953491211\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 117, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2914085388183594, Valid: 2.306065082550049\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 117, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.301830530166626, Valid: 2.3040640354156494\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 117, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299046277999878, Valid: 2.304981231689453\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 118, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.300854444503784, Valid: 2.3026039600372314\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 118, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3020308017730713, Valid: 2.3036868572235107\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.09699998795986176\n",
      "Epoch 118, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.291552782058716, Valid: 2.3065967559814453\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 118, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3013596534729004, Valid: 2.304266929626465\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 118, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2991983890533447, Valid: 2.3052496910095215\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 119, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3002567291259766, Valid: 2.302658796310425\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 119, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.300698757171631, Valid: 2.303615093231201\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.09699998795986176\n",
      "Epoch 119, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2917637825012207, Valid: 2.3072757720947266\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 119, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300787925720215, Valid: 2.3044815063476562\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 119, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2993929386138916, Valid: 2.3055579662323\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 120, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2997498512268066, Valid: 2.3027760982513428\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 120, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2999086380004883, Valid: 2.303410530090332\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 120, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.291456699371338, Valid: 2.3079843521118164\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 120, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2995543479919434, Valid: 2.304664134979248\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 120, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299639940261841, Valid: 2.305928945541382\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 121, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2993388175964355, Valid: 2.3028626441955566\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 121, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2981791496276855, Valid: 2.3032004833221436\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 121, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.291085958480835, Valid: 2.30873966217041\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 121, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.298383951187134, Valid: 2.3049156665802\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 121, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299969434738159, Valid: 2.3063511848449707\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 122, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.299027919769287, Valid: 2.3029584884643555\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999906539917\n",
      "Epoch 122, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2967333793640137, Valid: 2.302966833114624\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 122, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.290595054626465, Valid: 2.3094706535339355\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 122, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2975659370422363, Valid: 2.3051185607910156\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 122, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300182342529297, Valid: 2.30680513381958\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 123, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2989091873168945, Valid: 2.3030667304992676\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 123, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2945640087127686, Valid: 2.30281925201416\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 123, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.289734363555908, Valid: 2.310223340988159\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 123, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2963802814483643, Valid: 2.3053157329559326\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 123, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3004846572875977, Valid: 2.3073110580444336\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n",
      "Epoch 124, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2985198497772217, Valid: 2.303215742111206\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 124, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2927722930908203, Valid: 2.3027455806732178\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 124, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2888073921203613, Valid: 2.3110034465789795\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 124, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2956743240356445, Valid: 2.3054983615875244\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 124, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3006272315979004, Valid: 2.3078436851501465\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2988126277923584, Valid: 2.3033175468444824\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 125, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2909860610961914, Valid: 2.3027286529541016\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 125, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.287703275680542, Valid: 2.3117692470550537\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 125, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2950639724731445, Valid: 2.3055384159088135\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 125, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300872802734375, Valid: 2.308353900909424\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 126, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2990405559539795, Valid: 2.3034913539886475\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 126, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.28879976272583, Valid: 2.302851676940918\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 126, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2873454093933105, Valid: 2.312645435333252\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 126, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.29518461227417, Valid: 2.3056108951568604\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 126, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301090717315674, Valid: 2.3088583946228027\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 127, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.299406051635742, Valid: 2.30373215675354\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 127, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.286478281021118, Valid: 2.3030972480773926\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 127, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2869389057159424, Valid: 2.3134803771972656\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 127, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2952418327331543, Valid: 2.3053765296936035\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 127, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.301424741744995, Valid: 2.3093628883361816\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499998927116394\n",
      "Epoch 128, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.299903154373169, Valid: 2.3040151596069336\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 128, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.283696174621582, Valid: 2.3035500049591064\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.0997999906539917\n",
      "Epoch 128, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.286959171295166, Valid: 2.314399242401123\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 128, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.295801877975464, Valid: 2.3051793575286865\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999981045723\n",
      "Epoch 128, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3010993003845215, Valid: 2.310040235519409\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 129, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3005194664001465, Valid: 2.3042590618133545\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 129, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2812232971191406, Valid: 2.304023027420044\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 129, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2875478267669678, Valid: 2.3157079219818115\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 129, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.296450138092041, Valid: 2.3048925399780273\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999906539917\n",
      "Epoch 129, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300893545150757, Valid: 2.3105406761169434\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499998927116394\n",
      "Epoch 130, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.301159381866455, Valid: 2.3045666217803955\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 130, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.278272867202759, Valid: 2.304722309112549\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 130, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2883336544036865, Valid: 2.3158321380615234\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 130, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.297292470932007, Valid: 2.3046693801879883\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999981045723\n",
      "Epoch 130, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3010385036468506, Valid: 2.3111789226531982\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 131, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.301609754562378, Valid: 2.3048291206359863\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 131, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.275803565979004, Valid: 2.3054556846618652\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 131, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.290119171142578, Valid: 2.316558361053467\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 131, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2979736328125, Valid: 2.304443359375\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999981045723\n",
      "Epoch 131, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3016531467437744, Valid: 2.31205153465271\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 132, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3024086952209473, Valid: 2.305136203765869\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 132, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.273163318634033, Valid: 2.3063650131225586\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 132, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2919554710388184, Valid: 2.3168160915374756\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 132, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2991623878479004, Valid: 2.3043041229248047\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999906539917\n",
      "Epoch 132, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3010058403015137, Valid: 2.3119735717773438\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 133, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.302917003631592, Valid: 2.3052847385406494\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 133, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2697839736938477, Valid: 2.3076705932617188\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 133, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.295198917388916, Valid: 2.3178186416625977\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 133, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2996890544891357, Valid: 2.304313898086548\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999906539917\n",
      "Epoch 133, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3008031845092773, Valid: 2.3121025562286377\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 134, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3033692836761475, Valid: 2.3053882122039795\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 134, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.26829195022583, Valid: 2.308363676071167\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 134, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2978124618530273, Valid: 2.3179831504821777\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 134, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300330638885498, Valid: 2.3045034408569336\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999906539917\n",
      "Epoch 134, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300781011581421, Valid: 2.312019109725952\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 135, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3035824298858643, Valid: 2.305421829223633\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 135, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2662034034729004, Valid: 2.309337615966797\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 135, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.3010332584381104, Valid: 2.3185102939605713\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 135, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300723075866699, Valid: 2.3049700260162354\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999981045723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3005855083465576, Valid: 2.311720848083496\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 136, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.30367374420166, Valid: 2.3054022789001465\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 136, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.264359712600708, Valid: 2.3102550506591797\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 136, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.296849489212036, Valid: 2.3184707164764404\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 136, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300614356994629, Valid: 2.305696725845337\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999981045723\n",
      "Epoch 136, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300400733947754, Valid: 2.3112967014312744\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 137, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3034729957580566, Valid: 2.305149793624878\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 137, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.262629985809326, Valid: 2.3108339309692383\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 137, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.307521104812622, Valid: 2.3191897869110107\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 137, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300520420074463, Valid: 2.3071646690368652\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999981045723\n",
      "Epoch 137, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300537347793579, Valid: 2.310828924179077\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 138, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3030543327331543, Valid: 2.30488920211792\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 138, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.261380672454834, Valid: 2.311383008956909\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 138, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.3074898719787598, Valid: 2.319145917892456\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 138, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3002705574035645, Valid: 2.307896375656128\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.0997999906539917\n",
      "Epoch 138, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3005270957946777, Valid: 2.3104636669158936\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 139, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.302122116088867, Valid: 2.3046889305114746\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 139, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2603647708892822, Valid: 2.311645746231079\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 139, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.3100802898406982, Valid: 2.3201122283935547\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 139, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2999942302703857, Valid: 2.309270143508911\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 139, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300856590270996, Valid: 2.3101699352264404\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 140, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.301846981048584, Valid: 2.3046200275421143\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 140, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.259244680404663, Valid: 2.311697483062744\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 140, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.3082435131073, Valid: 2.319169759750366\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 140, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2985212802886963, Valid: 2.3106679916381836\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 140, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3012890815734863, Valid: 2.3099708557128906\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 141, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.301499366760254, Valid: 2.3046634197235107\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 141, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2589457035064697, Valid: 2.31186580657959\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 141, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.306694269180298, Valid: 2.318983554840088\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 141, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2971034049987793, Valid: 2.312427282333374\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 141, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3020472526550293, Valid: 2.3099734783172607\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 142, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.300973892211914, Valid: 2.3047330379486084\n",
      "Accuracy = Train: 0.125 Valid: 0.10199999064207077\n",
      "Epoch 142, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.258173942565918, Valid: 2.311823844909668\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 142, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.305670976638794, Valid: 2.3191092014312744\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 142, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.295862913131714, Valid: 2.3136980533599854\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 142, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.302534341812134, Valid: 2.3100991249084473\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 143, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3005995750427246, Valid: 2.304982900619507\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 143, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.258819103240967, Valid: 2.3115782737731934\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 143, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.303359270095825, Valid: 2.3190665245056152\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 143, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.294562578201294, Valid: 2.3148937225341797\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 143, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3037967681884766, Valid: 2.3104469776153564\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 144, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3002545833587646, Valid: 2.30525803565979\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 144, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.259213447570801, Valid: 2.3112542629241943\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 144, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.3008875846862793, Valid: 2.3192760944366455\n",
      "Accuracy = Train: 0.05000000074505806 Valid: 0.09459999948740005\n",
      "Epoch 144, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2933478355407715, Valid: 2.3159708976745605\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 144, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.304065704345703, Valid: 2.3106772899627686\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 145, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.300072431564331, Valid: 2.305604934692383\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 145, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.25958251953125, Valid: 2.3111274242401123\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 145, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2982630729675293, Valid: 2.3195815086364746\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 145, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2923669815063477, Valid: 2.31697678565979\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 145, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.303835868835449, Valid: 2.311171531677246\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 146, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.29976749420166, Valid: 2.306046485900879\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 146, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2599799633026123, Valid: 2.311227321624756\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 146, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2958781719207764, Valid: 2.3197295665740967\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 146, CIFAR-10 Batch 4: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = Train: 2.291679859161377, Valid: 2.317697048187256\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 146, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3036203384399414, Valid: 2.311638832092285\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 147, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.29950213432312, Valid: 2.3065130710601807\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 147, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2605209350585938, Valid: 2.311424493789673\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 147, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2928109169006348, Valid: 2.320225715637207\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 147, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2913289070129395, Valid: 2.3180696964263916\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 147, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3029613494873047, Valid: 2.3122663497924805\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 148, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2992677688598633, Valid: 2.306976318359375\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 148, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.261207103729248, Valid: 2.311861515045166\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 148, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2900888919830322, Valid: 2.3204822540283203\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 148, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2908401489257812, Valid: 2.3182575702667236\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 148, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3019940853118896, Valid: 2.3129708766937256\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 149, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2990527153015137, Valid: 2.307490587234497\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 149, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2618346214294434, Valid: 2.312246084213257\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 149, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.288069486618042, Valid: 2.3206629753112793\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 149, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2916250228881836, Valid: 2.3182034492492676\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 149, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.300830125808716, Valid: 2.313721179962158\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 150, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2986934185028076, Valid: 2.3080906867980957\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 150, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.263078212738037, Valid: 2.312809944152832\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 150, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2846226692199707, Valid: 2.3210272789001465\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 150, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.293015241622925, Valid: 2.318110942840576\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 150, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299612522125244, Valid: 2.3145546913146973\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 151, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.298741340637207, Valid: 2.3088274002075195\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 151, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2637999057769775, Valid: 2.313812732696533\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 151, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2825727462768555, Valid: 2.3206381797790527\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 151, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2938477993011475, Valid: 2.3179094791412354\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 151, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2983994483947754, Valid: 2.3153271675109863\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 152, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2987446784973145, Valid: 2.3092727661132812\n",
      "Accuracy = Train: 0.125 Valid: 0.10499999672174454\n",
      "Epoch 152, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2650671005249023, Valid: 2.3145949840545654\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 152, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.280531406402588, Valid: 2.320600986480713\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 152, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.29506516456604, Valid: 2.318194627761841\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.09459999948740005\n",
      "Epoch 152, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.297180652618408, Valid: 2.31618595123291\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 153, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.298827648162842, Valid: 2.3100056648254395\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 153, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2664201259613037, Valid: 2.315641403198242\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 153, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.278700113296509, Valid: 2.3205976486206055\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 153, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.297274112701416, Valid: 2.317471981048584\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 153, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2961037158966064, Valid: 2.3167569637298584\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 154, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.299720287322998, Valid: 2.311363697052002\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 154, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2685511112213135, Valid: 2.3166706562042236\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 154, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2771618366241455, Valid: 2.3205301761627197\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 154, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2997612953186035, Valid: 2.3172807693481445\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 154, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2950279712677, Valid: 2.3173813819885254\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 155, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.299081563949585, Valid: 2.311650276184082\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 155, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.268860340118408, Valid: 2.317988634109497\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 155, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.275390863418579, Valid: 2.3205642700195312\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 155, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3012900352478027, Valid: 2.316774368286133\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 155, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.293762445449829, Valid: 2.3176705837249756\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 156, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.299170970916748, Valid: 2.312570571899414\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 156, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2696266174316406, Valid: 2.3191704750061035\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 156, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.273996114730835, Valid: 2.3205320835113525\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 156, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3030941486358643, Valid: 2.316190004348755\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 156, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2927467823028564, Valid: 2.3178062438964844\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 157, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.2995567321777344, Valid: 2.313544988632202\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 157, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2699875831604004, Valid: 2.320484161376953\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 157, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.272641897201538, Valid: 2.320448398590088\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 157, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.304638624191284, Valid: 2.3154547214508057\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.292092800140381, Valid: 2.317617416381836\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 158, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.299661636352539, Valid: 2.3145687580108643\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 158, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.269887685775757, Valid: 2.3219666481018066\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 158, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2713518142700195, Valid: 2.320427656173706\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 158, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.305964946746826, Valid: 2.3145551681518555\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 158, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2912328243255615, Valid: 2.3176140785217285\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 159, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.299781560897827, Valid: 2.3158559799194336\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 159, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.269315004348755, Valid: 2.3235726356506348\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 159, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.270787477493286, Valid: 2.3201889991760254\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 159, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3069450855255127, Valid: 2.3132283687591553\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 159, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.290768623352051, Valid: 2.3171725273132324\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 160, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.300299644470215, Valid: 2.317063808441162\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 160, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2684221267700195, Valid: 2.3253653049468994\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 160, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2705111503601074, Valid: 2.320242404937744\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 160, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307568073272705, Valid: 2.312366247177124\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 160, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2902426719665527, Valid: 2.3168482780456543\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 161, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3003244400024414, Valid: 2.3186194896698\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 161, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2669334411621094, Valid: 2.327686309814453\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 161, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2709591388702393, Valid: 2.320525884628296\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 161, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307828903198242, Valid: 2.311201333999634\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 161, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2900140285491943, Valid: 2.316624641418457\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 162, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.30151629447937, Valid: 2.3203399181365967\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 162, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2651028633117676, Valid: 2.329724073410034\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 162, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.273061513900757, Valid: 2.3204398155212402\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 162, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.30806040763855, Valid: 2.310253858566284\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 162, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2903292179107666, Valid: 2.3165297508239746\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 163, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3007302284240723, Valid: 2.320348024368286\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 163, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2632675170898438, Valid: 2.332091808319092\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 163, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.274057626724243, Valid: 2.3210794925689697\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 163, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3083231449127197, Valid: 2.308607578277588\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 163, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.289884567260742, Valid: 2.315789222717285\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 164, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3016510009765625, Valid: 2.3215818405151367\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 164, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2610816955566406, Valid: 2.3348445892333984\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 164, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.276273488998413, Valid: 2.321241617202759\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 164, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3067026138305664, Valid: 2.30810284614563\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 164, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2900240421295166, Valid: 2.3151962757110596\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 165, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3020169734954834, Valid: 2.3225138187408447\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 165, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.258579969406128, Valid: 2.3371851444244385\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 165, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.279282808303833, Valid: 2.321629762649536\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 165, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.306511402130127, Valid: 2.3075027465820312\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 165, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.289750814437866, Valid: 2.3148951530456543\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 166, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3026795387268066, Valid: 2.3233025074005127\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 166, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2557573318481445, Valid: 2.339345693588257\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 166, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.282979965209961, Valid: 2.321976661682129\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 166, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.305746555328369, Valid: 2.3070807456970215\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 166, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2893810272216797, Valid: 2.314375877380371\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 167, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3034181594848633, Valid: 2.3241100311279297\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 167, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.252580404281616, Valid: 2.3413569927215576\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 167, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2884974479675293, Valid: 2.322533130645752\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 167, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3053369522094727, Valid: 2.3069872856140137\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 167, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2889158725738525, Valid: 2.313711166381836\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 168, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3041858673095703, Valid: 2.3247714042663574\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 168, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.249574661254883, Valid: 2.343363046646118\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 168, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2907276153564453, Valid: 2.322648286819458\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 168, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3044660091400146, Valid: 2.307018280029297\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 168, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2883105278015137, Valid: 2.3129000663757324\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3045756816864014, Valid: 2.3249692916870117\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 169, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2464025020599365, Valid: 2.3450775146484375\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 169, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2958147525787354, Valid: 2.322929859161377\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 169, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3041839599609375, Valid: 2.307415246963501\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 169, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.287410020828247, Valid: 2.312314748764038\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 170, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3061094284057617, Valid: 2.3260321617126465\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 170, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2442984580993652, Valid: 2.3460326194763184\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 170, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2966837882995605, Valid: 2.3230514526367188\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 170, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.304471492767334, Valid: 2.3080039024353027\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 170, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2864861488342285, Valid: 2.3114962577819824\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 171, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.307209014892578, Valid: 2.3266963958740234\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 171, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.241819143295288, Valid: 2.3457088470458984\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 171, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2706968784332275, Valid: 2.323216676712036\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 171, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3064682483673096, Valid: 2.3098907470703125\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 171, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2853753566741943, Valid: 2.3106448650360107\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 172, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3085873126983643, Valid: 2.3273017406463623\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 172, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.240417242050171, Valid: 2.3459603786468506\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 172, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.298654556274414, Valid: 2.3233962059020996\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 172, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.305488348007202, Valid: 2.3097949028015137\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 172, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2842931747436523, Valid: 2.310213565826416\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 173, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.310108184814453, Valid: 2.32784104347229\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 173, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2386789321899414, Valid: 2.345898151397705\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 173, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2982287406921387, Valid: 2.323005199432373\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 173, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.306698799133301, Valid: 2.31109356880188\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499998927116394\n",
      "Epoch 173, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2831337451934814, Valid: 2.309631586074829\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 174, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.311309814453125, Valid: 2.328683376312256\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 174, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.237575054168701, Valid: 2.345548391342163\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 174, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.296863079071045, Valid: 2.3227381706237793\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 174, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.309451103210449, Valid: 2.313105821609497\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 174, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2822086811065674, Valid: 2.3093719482421875\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 175, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3142032623291016, Valid: 2.331446886062622\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 175, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2370855808258057, Valid: 2.3450939655303955\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 175, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.294110059738159, Valid: 2.322628974914551\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 175, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.310129404067993, Valid: 2.3143248558044434\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 175, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2814183235168457, Valid: 2.3091840744018555\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 176, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3136866092681885, Valid: 2.3297924995422363\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 176, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.236947774887085, Valid: 2.3440792560577393\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 176, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.290254592895508, Valid: 2.3226113319396973\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10679998993873596\n",
      "Epoch 176, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3117780685424805, Valid: 2.3163394927978516\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 176, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2808494567871094, Valid: 2.3090128898620605\n",
      "Accuracy = Train: 0.125 Valid: 0.09780000150203705\n",
      "Epoch 177, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3148622512817383, Valid: 2.330324649810791\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 177, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2373805046081543, Valid: 2.343003273010254\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 177, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.284762144088745, Valid: 2.322826862335205\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 177, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.313309669494629, Valid: 2.318436622619629\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 177, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2807064056396484, Valid: 2.309006452560425\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 178, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.31577730178833, Valid: 2.330705165863037\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 178, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2382593154907227, Valid: 2.341920852661133\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 178, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2803049087524414, Valid: 2.323112964630127\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 178, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3151133060455322, Valid: 2.320775032043457\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 178, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2801525592803955, Valid: 2.3095407485961914\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 179, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316448450088501, Valid: 2.330860137939453\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 179, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2395436763763428, Valid: 2.3407094478607178\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 179, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.274902582168579, Valid: 2.3239047527313232\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 179, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3148133754730225, Valid: 2.3223586082458496\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 179, CIFAR-10 Batch 5: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = Train: 2.280526876449585, Valid: 2.31050968170166\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 180, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3165524005889893, Valid: 2.3306217193603516\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 180, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.242445707321167, Valid: 2.3387556076049805\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 180, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.268995761871338, Valid: 2.3247885704040527\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 180, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3148293495178223, Valid: 2.3240623474121094\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 180, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.281909942626953, Valid: 2.310913562774658\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 181, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3165433406829834, Valid: 2.3303613662719727\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 181, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2431130409240723, Valid: 2.3384227752685547\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 181, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.263615846633911, Valid: 2.326587677001953\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 181, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3145480155944824, Valid: 2.325545072555542\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 181, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.283308982849121, Valid: 2.312328577041626\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 182, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316343307495117, Valid: 2.3299272060394287\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 182, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.24527645111084, Valid: 2.337526321411133\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 182, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.258211135864258, Valid: 2.328636646270752\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 182, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3136820793151855, Valid: 2.326716661453247\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 182, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.284984588623047, Valid: 2.3136348724365234\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 183, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.315905809402466, Valid: 2.3293676376342773\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 183, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2475085258483887, Valid: 2.336803913116455\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 183, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.253072738647461, Valid: 2.3308629989624023\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 183, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3120994567871094, Valid: 2.3264012336730957\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 183, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.287252902984619, Valid: 2.3153176307678223\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 184, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.315438747406006, Valid: 2.328700542449951\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 184, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.249664783477783, Valid: 2.3360707759857178\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 184, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.248838424682617, Valid: 2.3328182697296143\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 184, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.310854196548462, Valid: 2.3282508850097656\n",
      "Accuracy = Train: 0.07500000298023224 Valid: 0.10499999672174454\n",
      "Epoch 184, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2896628379821777, Valid: 2.317225933074951\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 185, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3148603439331055, Valid: 2.3280158042907715\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 185, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2518012523651123, Valid: 2.335749387741089\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 185, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2435781955718994, Valid: 2.3363876342773438\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 185, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.308736562728882, Valid: 2.3287672996520996\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 185, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2915663719177246, Valid: 2.3196234703063965\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 186, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3139636516571045, Valid: 2.3273308277130127\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 186, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.254336357116699, Valid: 2.3334648609161377\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 186, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2406935691833496, Valid: 2.3378477096557617\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 186, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3072919845581055, Valid: 2.3290374279022217\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 186, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.293916940689087, Valid: 2.3206233978271484\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 187, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3140668869018555, Valid: 2.3268661499023438\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 187, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2564008235931396, Valid: 2.3376991748809814\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 187, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.237272262573242, Valid: 2.34025239944458\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 187, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.305241107940674, Valid: 2.3294506072998047\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 187, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.2967593669891357, Valid: 2.3224637508392334\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 188, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.313330888748169, Valid: 2.326137065887451\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 188, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2586145401000977, Valid: 2.3378286361694336\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 188, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2322051525115967, Valid: 2.345337390899658\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 188, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.304013252258301, Valid: 2.32974910736084\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 188, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.299051284790039, Valid: 2.3238189220428467\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 189, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.310343027114868, Valid: 2.3232192993164062\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999981045723\n",
      "Epoch 189, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2587478160858154, Valid: 2.335369348526001\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 189, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2327475547790527, Valid: 2.343994140625\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 189, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3026676177978516, Valid: 2.330004930496216\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 189, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3027329444885254, Valid: 2.326784610748291\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 190, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3115668296813965, Valid: 2.3245291709899902\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999981045723\n",
      "Epoch 190, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.260540008544922, Valid: 2.33558988571167\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 190, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2306859493255615, Valid: 2.3457820415496826\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3008151054382324, Valid: 2.3301024436950684\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 190, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3028573989868164, Valid: 2.3264682292938232\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.10499999672174454\n",
      "Epoch 191, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.312208652496338, Valid: 2.324277400970459\n",
      "Accuracy = Train: 0.125 Valid: 0.0997999981045723\n",
      "Epoch 191, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2624356746673584, Valid: 2.33579683303833\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 191, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.227889060974121, Valid: 2.349154233932495\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 191, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3002736568450928, Valid: 2.3311588764190674\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 191, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3043665885925293, Valid: 2.327526569366455\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 192, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.312060832977295, Valid: 2.3240413665771484\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 192, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2639312744140625, Valid: 2.336104393005371\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 192, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2278640270233154, Valid: 2.3482444286346436\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 192, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.299598455429077, Valid: 2.3318891525268555\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 192, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3073408603668213, Valid: 2.3292672634124756\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 193, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.311810255050659, Valid: 2.3238258361816406\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 193, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2654571533203125, Valid: 2.3364930152893066\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 193, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2270658016204834, Valid: 2.3492939472198486\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 193, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.298980474472046, Valid: 2.3323583602905273\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 193, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3072211742401123, Valid: 2.3293404579162598\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 194, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.311631202697754, Valid: 2.3240699768066406\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 194, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.266714334487915, Valid: 2.3370041847229004\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 194, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2265076637268066, Valid: 2.3503127098083496\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 194, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2984421253204346, Valid: 2.3327887058258057\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 194, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3089137077331543, Valid: 2.3328466415405273\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 195, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.311940908432007, Valid: 2.3240880966186523\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 195, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2682113647460938, Valid: 2.3373942375183105\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 195, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.226376533508301, Valid: 2.351250648498535\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 195, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2980167865753174, Valid: 2.3331525325775146\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 195, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3095226287841797, Valid: 2.3307180404663086\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 196, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3116798400878906, Valid: 2.323995590209961\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 196, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2691869735717773, Valid: 2.337803840637207\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 196, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.225679397583008, Valid: 2.3525261878967285\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 196, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2975950241088867, Valid: 2.333360433578491\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 196, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3102431297302246, Valid: 2.3310742378234863\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 197, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3116276264190674, Valid: 2.3241589069366455\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 197, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2700910568237305, Valid: 2.338191032409668\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 197, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2428040504455566, Valid: 2.350306272506714\n",
      "Accuracy = Train: 0.15000000596046448 Valid: 0.0997999906539917\n",
      "Epoch 197, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3016180992126465, Valid: 2.3313357830047607\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 197, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3085787296295166, Valid: 2.329296588897705\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 198, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3121466636657715, Valid: 2.3240840435028076\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 198, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2687788009643555, Valid: 2.338428020477295\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 198, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.228961229324341, Valid: 2.3505215644836426\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 198, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.299556016921997, Valid: 2.3333280086517334\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 198, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3097264766693115, Valid: 2.3300724029541016\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 199, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.312284231185913, Valid: 2.3243303298950195\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 199, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2699716091156006, Valid: 2.3388421535491943\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 199, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.229670763015747, Valid: 2.3511109352111816\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 199, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2990095615386963, Valid: 2.333420753479004\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 199, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3107850551605225, Valid: 2.3308820724487305\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 200, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3122472763061523, Valid: 2.3245575428009033\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 200, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270850658416748, Valid: 2.339099884033203\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 200, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.228853464126587, Valid: 2.3529598712921143\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 200, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.299311637878418, Valid: 2.335022211074829\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 200, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3116977214813232, Valid: 2.331399440765381\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 201, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3123104572296143, Valid: 2.3247714042663574\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 201, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2714996337890625, Valid: 2.3392276763916016\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 201, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.229384660720825, Valid: 2.3539514541625977\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.298029661178589, Valid: 2.3340866565704346\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 201, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.312253713607788, Valid: 2.331846237182617\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 202, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.312525987625122, Valid: 2.325101613998413\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 202, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2719995975494385, Valid: 2.33941388130188\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 202, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2300333976745605, Valid: 2.3548965454101562\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 202, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.297886610031128, Valid: 2.3344130516052246\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 202, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3129568099975586, Valid: 2.3322103023529053\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 203, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3125829696655273, Valid: 2.324803113937378\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 203, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2720487117767334, Valid: 2.339399814605713\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 203, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2307679653167725, Valid: 2.355560779571533\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 203, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.297837257385254, Valid: 2.334754467010498\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 203, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.313304901123047, Valid: 2.3323326110839844\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 204, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.312598466873169, Valid: 2.3254969120025635\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 204, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.272212028503418, Valid: 2.3394603729248047\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 204, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2314765453338623, Valid: 2.3563485145568848\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 204, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.297940731048584, Valid: 2.335195541381836\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 204, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3138887882232666, Valid: 2.332573652267456\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 205, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3151729106903076, Valid: 2.3254408836364746\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 205, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.273002862930298, Valid: 2.3398773670196533\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 205, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.232496738433838, Valid: 2.3521535396575928\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 205, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.297074556350708, Valid: 2.334981918334961\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 205, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.314307928085327, Valid: 2.33266019821167\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 206, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.312760353088379, Valid: 2.325711727142334\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 206, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2720861434936523, Valid: 2.339536666870117\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 206, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2330000400543213, Valid: 2.35749888420105\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 206, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.298532009124756, Valid: 2.336249828338623\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 206, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3147201538085938, Valid: 2.3327577114105225\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 207, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.324552297592163, Valid: 2.333852529525757\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 207, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.291619300842285, Valid: 2.339641571044922\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 207, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.234550714492798, Valid: 2.3573875427246094\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 207, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2993483543395996, Valid: 2.3363094329833984\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 207, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3140928745269775, Valid: 2.332397222518921\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 208, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.313680410385132, Valid: 2.3259685039520264\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 208, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2716431617736816, Valid: 2.3403353691101074\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 208, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.234290361404419, Valid: 2.3582475185394287\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 208, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.2999491691589355, Valid: 2.337299108505249\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 208, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3145251274108887, Valid: 2.3324811458587646\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 209, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.313931465148926, Valid: 2.326192855834961\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 209, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.271646022796631, Valid: 2.3391852378845215\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 209, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2348790168762207, Valid: 2.358736991882324\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 209, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.300473213195801, Valid: 2.338163137435913\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 209, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.315120220184326, Valid: 2.3326451778411865\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 210, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3141233921051025, Valid: 2.32639741897583\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 210, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.271493434906006, Valid: 2.3390963077545166\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 210, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2354395389556885, Valid: 2.3591957092285156\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 210, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.301055908203125, Valid: 2.339049816131592\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 210, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.315641403198242, Valid: 2.3327672481536865\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 211, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.314321756362915, Valid: 2.3265862464904785\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 211, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.271440029144287, Valid: 2.3391354084014893\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 211, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.23642897605896, Valid: 2.354780673980713\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 211, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3006060123443604, Valid: 2.3402259349823\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 211, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.315682888031006, Valid: 2.332263946533203\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 212, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3149373531341553, Valid: 2.326796770095825\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 212, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2746517658233643, Valid: 2.342067241668701\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 212, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.236793041229248, Valid: 2.359245538711548\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3033413887023926, Valid: 2.340430974960327\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 212, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.314969062805176, Valid: 2.3322908878326416\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 213, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3141367435455322, Valid: 2.3272056579589844\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 213, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.271146059036255, Valid: 2.3389816284179688\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 213, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.23714017868042, Valid: 2.3596115112304688\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 213, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3035900592803955, Valid: 2.3410656452178955\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 213, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.315600633621216, Valid: 2.3324456214904785\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 214, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.315402030944824, Valid: 2.326904296875\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 214, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2709901332855225, Valid: 2.3388049602508545\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 214, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2373604774475098, Valid: 2.3599305152893066\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 214, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.303994655609131, Valid: 2.341965436935425\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 214, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3159279823303223, Valid: 2.3323211669921875\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 215, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3152549266815186, Valid: 2.3269526958465576\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 215, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2708845138549805, Valid: 2.338743209838867\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 215, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2376036643981934, Valid: 2.360193967819214\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 215, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.304396152496338, Valid: 2.342714309692383\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 215, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3163695335388184, Valid: 2.33268141746521\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 216, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.315901041030884, Valid: 2.3272705078125\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 216, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2708683013916016, Valid: 2.338714122772217\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 216, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2377772331237793, Valid: 2.3604328632354736\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 216, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.30479097366333, Valid: 2.343428134918213\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 216, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3166983127593994, Valid: 2.332801342010498\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 217, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3157601356506348, Valid: 2.3273797035217285\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 217, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270711660385132, Valid: 2.3386430740356445\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 217, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.23795223236084, Valid: 2.3606295585632324\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 217, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3051633834838867, Valid: 2.3440980911254883\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 217, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.316983461380005, Valid: 2.33288836479187\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 218, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.315899610519409, Valid: 2.3275179862976074\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 218, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2706356048583984, Valid: 2.3385977745056152\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 218, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238097906112671, Valid: 2.360780954360962\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 218, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.305497407913208, Valid: 2.3446812629699707\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 218, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3172097206115723, Valid: 2.3329579830169678\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 219, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316039562225342, Valid: 2.3276445865631104\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 219, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.273247241973877, Valid: 2.337559461593628\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 219, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2385597229003906, Valid: 2.3604869842529297\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 219, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3058907985687256, Valid: 2.345155715942383\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 219, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317307949066162, Valid: 2.3329415321350098\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 220, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3162431716918945, Valid: 2.3277409076690674\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 220, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704415321350098, Valid: 2.3385584354400635\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 220, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238384485244751, Valid: 2.360844612121582\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 220, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3055858612060547, Valid: 2.346208095550537\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 220, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317415475845337, Valid: 2.333085536956787\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 221, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3163704872131348, Valid: 2.327810049057007\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 221, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270416736602783, Valid: 2.338531494140625\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 221, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238386869430542, Valid: 2.361022472381592\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 221, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3063907623291016, Valid: 2.3459370136260986\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 221, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.31754207611084, Valid: 2.3330705165863037\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 222, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.31648850440979, Valid: 2.327908754348755\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 222, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703945636749268, Valid: 2.3384995460510254\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 222, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2384588718414307, Valid: 2.3610756397247314\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 222, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3065545558929443, Valid: 2.3462414741516113\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 222, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3176379203796387, Valid: 2.3331050872802734\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 223, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316450357437134, Valid: 2.3282277584075928\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 223, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2701985836029053, Valid: 2.338369369506836\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 223, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2385270595550537, Valid: 2.3610472679138184\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.306705951690674, Valid: 2.3464467525482178\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 223, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3175323009490967, Valid: 2.333033323287964\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 224, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316728353500366, Valid: 2.32808518409729\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 224, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703394889831543, Valid: 2.338456153869629\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 224, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2386069297790527, Valid: 2.3610799312591553\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 224, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3068201541900635, Valid: 2.3466625213623047\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 224, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3176157474517822, Valid: 2.333071231842041\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 225, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3167951107025146, Valid: 2.328148126602173\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 225, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703304290771484, Valid: 2.3384368419647217\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 225, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238649368286133, Valid: 2.361097574234009\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 225, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.306908369064331, Valid: 2.3468403816223145\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 225, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3176846504211426, Valid: 2.333103895187378\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 226, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316852569580078, Valid: 2.32820200920105\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 226, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270568370819092, Valid: 2.3389647006988525\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 226, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2386231422424316, Valid: 2.3612234592437744\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 226, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3069992065429688, Valid: 2.346991777420044\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 226, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317725896835327, Valid: 2.3331313133239746\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 227, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316582202911377, Valid: 2.32810378074646\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 227, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270230531692505, Valid: 2.338541030883789\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 227, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2386474609375, Valid: 2.361248731613159\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 227, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3070456981658936, Valid: 2.347118616104126\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 227, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3183677196502686, Valid: 2.33347225189209\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 228, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3167009353637695, Valid: 2.3280980587005615\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 228, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270378589630127, Valid: 2.3384222984313965\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 228, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387590408325195, Valid: 2.361273765563965\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 228, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3071160316467285, Valid: 2.347055435180664\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 228, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3174877166748047, Valid: 2.333061933517456\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 229, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171472549438477, Valid: 2.3282687664031982\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 229, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270388603210449, Valid: 2.338412284851074\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 229, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2391388416290283, Valid: 2.361095428466797\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 229, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307246446609497, Valid: 2.3470702171325684\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 229, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3174355030059814, Valid: 2.33304500579834\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 230, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317167282104492, Valid: 2.3283324241638184\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 230, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704153060913086, Valid: 2.338374137878418\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 230, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387845516204834, Valid: 2.3612616062164307\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 230, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307119846343994, Valid: 2.347245454788208\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 230, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3175225257873535, Valid: 2.333087921142578\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 231, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171615600585938, Valid: 2.3283591270446777\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 231, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704055309295654, Valid: 2.338362693786621\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 231, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387938499450684, Valid: 2.3612594604492188\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 231, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3071467876434326, Valid: 2.3473198413848877\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 231, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317601442337036, Valid: 2.3331267833709717\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 232, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171591758728027, Valid: 2.3283824920654297\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 232, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270397186279297, Valid: 2.338352918624878\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 232, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238804340362549, Valid: 2.361250162124634\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 232, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3071696758270264, Valid: 2.3473799228668213\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 232, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3176732063293457, Valid: 2.333160877227783\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 233, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317155361175537, Valid: 2.3284010887145996\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 233, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270390033721924, Valid: 2.338345766067505\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 233, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.23881459236145, Valid: 2.361237049102783\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 233, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3071882724761963, Valid: 2.3474268913269043\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 233, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317748546600342, Valid: 2.333195924758911\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 234, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171427249908447, Valid: 2.328416347503662\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 234, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703819274902344, Valid: 2.3383431434631348\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 234, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238830327987671, Valid: 2.361213207244873\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3072125911712646, Valid: 2.3474583625793457\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 234, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3177976608276367, Valid: 2.3332176208496094\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 235, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171544075012207, Valid: 2.328425407409668\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 235, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703773975372314, Valid: 2.3383352756500244\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 235, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238839626312256, Valid: 2.361198663711548\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 235, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307224750518799, Valid: 2.347490072250366\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 235, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3178505897521973, Valid: 2.3332419395446777\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 236, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171470165252686, Valid: 2.328434705734253\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 236, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703728675842285, Valid: 2.338329792022705\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 236, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.23884916305542, Valid: 2.3611810207366943\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 236, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307234048843384, Valid: 2.347515106201172\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 236, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3178999423980713, Valid: 2.333263874053955\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 237, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3186089992523193, Valid: 2.3296449184417725\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 237, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2707605361938477, Valid: 2.33835506439209\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 237, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238741397857666, Valid: 2.361335277557373\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 237, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307192087173462, Valid: 2.347562074661255\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 237, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317807674407959, Valid: 2.333256721496582\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 238, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317164182662964, Valid: 2.3284177780151367\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 238, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704145908355713, Valid: 2.3383169174194336\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 238, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387802600860596, Valid: 2.361283779144287\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 238, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307220458984375, Valid: 2.3475775718688965\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 238, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3178751468658447, Valid: 2.333279609680176\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 239, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317150592803955, Valid: 2.328428268432617\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 239, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2858211994171143, Valid: 2.343576192855835\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 239, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238877773284912, Valid: 2.361252546310425\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 239, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307079553604126, Valid: 2.347654104232788\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 239, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3180837631225586, Valid: 2.3334457874298096\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 240, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3165977001190186, Valid: 2.3279166221618652\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 240, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270542860031128, Valid: 2.3384058475494385\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 240, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2388217449188232, Valid: 2.3612241744995117\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 240, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3072285652160645, Valid: 2.347432851791382\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 240, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317610025405884, Valid: 2.3331947326660156\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 241, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316990375518799, Valid: 2.32818603515625\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 241, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270514726638794, Valid: 2.338411808013916\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 241, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238807201385498, Valid: 2.361210823059082\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 241, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307234525680542, Valid: 2.347484588623047\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 241, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317729949951172, Valid: 2.3332438468933105\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 242, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170108795166016, Valid: 2.3282470703125\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 242, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270476818084717, Valid: 2.3383898735046387\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 242, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2403371334075928, Valid: 2.3648171424865723\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 242, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307196617126465, Valid: 2.3471899032592773\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 242, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317758083343506, Valid: 2.3331751823425293\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 243, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3168210983276367, Valid: 2.3281497955322266\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 243, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270404100418091, Valid: 2.3384335041046143\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 243, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2386887073516846, Valid: 2.3612256050109863\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 243, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3070569038391113, Valid: 2.347296714782715\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 243, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317836284637451, Valid: 2.333249092102051\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 244, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316880226135254, Valid: 2.3282179832458496\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 244, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270392894744873, Valid: 2.338405132293701\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 244, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2386953830718994, Valid: 2.361248731613159\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 244, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307105302810669, Valid: 2.3473947048187256\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 244, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317920684814453, Valid: 2.333286762237549\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 245, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3169214725494385, Valid: 2.328268051147461\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 245, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704176902770996, Valid: 2.3384408950805664\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 245, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238300323486328, Valid: 2.3507792949676514\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3056039810180664, Valid: 2.3466761112213135\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 245, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3231470584869385, Valid: 2.335972309112549\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 246, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3174142837524414, Valid: 2.328188896179199\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 246, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270479679107666, Valid: 2.3382978439331055\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 246, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238867998123169, Valid: 2.3610951900482178\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 246, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3074541091918945, Valid: 2.3477792739868164\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 246, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.322183847427368, Valid: 2.3395256996154785\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 247, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170127868652344, Valid: 2.3282666206359863\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 247, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704734802246094, Valid: 2.3384132385253906\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 247, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.239041566848755, Valid: 2.360774278640747\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 247, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.30770206451416, Valid: 2.3475496768951416\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 247, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3166282176971436, Valid: 2.332519292831421\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 248, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317544937133789, Valid: 2.3284454345703125\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 248, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704973220825195, Valid: 2.3382983207702637\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 248, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238948345184326, Valid: 2.360882043838501\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 248, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3076252937316895, Valid: 2.347599744796753\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 248, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.316981792449951, Valid: 2.3327202796936035\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 249, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3174407482147217, Valid: 2.3284435272216797\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 249, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270460844039917, Valid: 2.3382983207702637\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 249, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238877534866333, Valid: 2.360966682434082\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 249, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307565450668335, Valid: 2.3476357460021973\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 249, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3172521591186523, Valid: 2.3328702449798584\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 250, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3173601627349854, Valid: 2.3284430503845215\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 250, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704291343688965, Valid: 2.3382978439331055\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 250, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.23883056640625, Valid: 2.3610260486602783\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 250, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3075203895568848, Valid: 2.34765887260437\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 250, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3174614906311035, Valid: 2.3329834938049316\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 251, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317298650741577, Valid: 2.3284428119659424\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 251, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704029083251953, Valid: 2.3382978439331055\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 251, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238800287246704, Valid: 2.36106538772583\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 251, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3074862957000732, Valid: 2.3476743698120117\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 251, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3176229000091553, Valid: 2.333068370819092\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 252, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317251205444336, Valid: 2.3284432888031006\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 252, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703819274902344, Valid: 2.338296890258789\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 252, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387821674346924, Valid: 2.361090660095215\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 252, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3074615001678467, Valid: 2.347684860229492\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 252, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317748546600342, Valid: 2.333132743835449\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 253, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3172144889831543, Valid: 2.3284430503845215\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 253, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270364284515381, Valid: 2.3382976055145264\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 253, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387707233428955, Valid: 2.361104965209961\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 253, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3074426651000977, Valid: 2.3476898670196533\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 253, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3178462982177734, Valid: 2.333181381225586\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 254, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317185878753662, Valid: 2.3284432888031006\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 254, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703514099121094, Valid: 2.3382973670959473\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 254, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238766670227051, Valid: 2.361112356185913\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 254, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3074281215667725, Valid: 2.347691535949707\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 254, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3179221153259277, Valid: 2.3332173824310303\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 255, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317164182662964, Valid: 2.3284435272216797\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 255, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270340919494629, Valid: 2.3382973670959473\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 255, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387661933898926, Valid: 2.3611133098602295\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 255, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3074166774749756, Valid: 2.3476920127868652\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 255, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317981481552124, Valid: 2.3332457542419434\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 256, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317147970199585, Valid: 2.328444480895996\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 256, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2768046855926514, Valid: 2.332625389099121\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 256, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.236440658569336, Valid: 2.3607001304626465\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3066582679748535, Valid: 2.347827434539795\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 256, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.316502809524536, Valid: 2.33231258392334\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 257, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3172473907470703, Valid: 2.3284895420074463\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 257, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702760696411133, Valid: 2.3382444381713867\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 257, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238600969314575, Valid: 2.3607215881347656\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 257, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3071532249450684, Valid: 2.347774028778076\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 257, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.316937208175659, Valid: 2.332578182220459\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 258, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3172049522399902, Valid: 2.3284685611724854\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 258, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2766380310058594, Valid: 2.3436944484710693\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 258, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2383005619049072, Valid: 2.3608896732330322\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 258, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3071482181549072, Valid: 2.34751296043396\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 258, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.316499710083008, Valid: 2.3323328495025635\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 259, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317138195037842, Valid: 2.3284549713134766\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 259, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704834938049316, Valid: 2.338301420211792\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 259, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238856554031372, Valid: 2.3607656955718994\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 259, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.4241485595703125, Valid: 2.438784122467041\n",
      "Accuracy = Train: 0.125 Valid: 0.09699998795986176\n",
      "Epoch 259, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3135592937469482, Valid: 2.3369369506835938\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 260, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317194700241089, Valid: 2.328507423400879\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 260, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270918607711792, Valid: 2.338319778442383\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 260, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238807439804077, Valid: 2.3608784675598145\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 260, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307746410369873, Valid: 2.3462817668914795\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 260, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3149328231811523, Valid: 2.3318395614624023\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 261, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3178250789642334, Valid: 2.3280911445617676\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 261, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.3645951747894287, Valid: 2.4606616497039795\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 261, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.251959800720215, Valid: 2.3623251914978027\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 261, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3154866695404053, Valid: 2.3437857627868652\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 261, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.307882785797119, Valid: 2.3228940963745117\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 262, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3189759254455566, Valid: 2.3281748294830322\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 262, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.264233350753784, Valid: 2.3367230892181396\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 262, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2492573261260986, Valid: 2.3578593730926514\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 262, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3132483959198, Valid: 2.3441476821899414\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 262, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3092782497406006, Valid: 2.3251075744628906\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 263, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3194282054901123, Valid: 2.327730894088745\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 263, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2661263942718506, Valid: 2.337582588195801\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 263, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2462007999420166, Valid: 2.3583579063415527\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 263, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.312358856201172, Valid: 2.3450238704681396\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 263, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3107001781463623, Valid: 2.327080011367798\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 264, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.319559335708618, Valid: 2.3275539875030518\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 264, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2674849033355713, Valid: 2.338189125061035\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 264, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.243760824203491, Valid: 2.358973264694214\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 264, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.308994770050049, Valid: 2.3452303409576416\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 264, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.312082290649414, Valid: 2.3284053802490234\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 265, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.319566249847412, Valid: 2.327594757080078\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 265, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2682833671569824, Valid: 2.338520050048828\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 265, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.242297410964966, Valid: 2.3591859340667725\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 265, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.310633897781372, Valid: 2.3461174964904785\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 265, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.312913417816162, Valid: 2.329655885696411\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 266, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.319253444671631, Valid: 2.3276727199554443\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 266, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2689430713653564, Valid: 2.338733196258545\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 266, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2410011291503906, Valid: 2.3597958087921143\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 266, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3098561763763428, Valid: 2.3464760780334473\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 266, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3139452934265137, Valid: 2.330634355545044\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 267, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.318887710571289, Valid: 2.327754497528076\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 267, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2693867683410645, Valid: 2.3388099670410156\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 267, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2401301860809326, Valid: 2.360305070877075\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.309234142303467, Valid: 2.3467612266540527\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 267, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.314771890640259, Valid: 2.3313539028167725\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 268, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3185336589813232, Valid: 2.3278512954711914\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 268, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.269683361053467, Valid: 2.3388099670410156\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 268, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2395570278167725, Valid: 2.3607001304626465\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 268, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.308755397796631, Valid: 2.3469903469085693\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 268, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3154258728027344, Valid: 2.3318779468536377\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 269, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3182249069213867, Valid: 2.327946662902832\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 269, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2698848247528076, Valid: 2.33876895904541\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 269, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.239182472229004, Valid: 2.360992908477783\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 269, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3083975315093994, Valid: 2.3471696376800537\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 269, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.315938711166382, Valid: 2.33225679397583\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 270, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317394256591797, Valid: 2.3280200958251953\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 270, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703471183776855, Valid: 2.338731050491333\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 270, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238954544067383, Valid: 2.361078977584839\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 270, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3080806732177734, Valid: 2.347226142883301\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 270, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3163068294525146, Valid: 2.332472324371338\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 271, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317671775817871, Valid: 2.3280532360076904\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 271, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270036458969116, Valid: 2.338714122772217\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 271, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238757610321045, Valid: 2.3613128662109375\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 271, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307880163192749, Valid: 2.3473451137542725\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 271, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.316633701324463, Valid: 2.332689046859741\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 272, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3175275325775146, Valid: 2.3281211853027344\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 272, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.27011775970459, Valid: 2.338646650314331\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 272, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238650321960449, Valid: 2.3614349365234375\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 272, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307732105255127, Valid: 2.347435474395752\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 272, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.320378303527832, Valid: 2.336729049682617\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 273, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316912889480591, Valid: 2.327977180480957\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 273, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270151376724243, Valid: 2.338595151901245\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 273, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238595962524414, Valid: 2.3612987995147705\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 273, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307692527770996, Valid: 2.3473920822143555\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 273, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.316958427429199, Valid: 2.332836389541626\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 274, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317338466644287, Valid: 2.328209638595581\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 274, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270160675048828, Valid: 2.3385565280914307\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 274, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2385613918304443, Valid: 2.3613767623901367\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 274, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307605266571045, Valid: 2.3474626541137695\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 274, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317150115966797, Valid: 2.332946300506592\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 275, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317274570465088, Valid: 2.328249454498291\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 275, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270195722579956, Valid: 2.338517189025879\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 275, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2385449409484863, Valid: 2.361422300338745\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 275, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.30753755569458, Valid: 2.3475143909454346\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 275, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.31730318069458, Valid: 2.3330297470092773\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 276, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317225456237793, Valid: 2.328282594680786\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 276, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702200412750244, Valid: 2.3384850025177\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 276, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2385430335998535, Valid: 2.361443519592285\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 276, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3074870109558105, Valid: 2.347553014755249\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 276, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3174266815185547, Valid: 2.333092212677002\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 277, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317187786102295, Valid: 2.328307867050171\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 277, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270238161087036, Valid: 2.338458776473999\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 277, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238548994064331, Valid: 2.3614487648010254\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 277, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3074474334716797, Valid: 2.347580671310425\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 277, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3175272941589355, Valid: 2.3331403732299805\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 278, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317159652709961, Valid: 2.328328847885132\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 278, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702510356903076, Valid: 2.338437557220459\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 278, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2385611534118652, Valid: 2.3614420890808105\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307417631149292, Valid: 2.3476006984710693\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 278, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317610263824463, Valid: 2.3331778049468994\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 279, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171377182006836, Valid: 2.3283462524414062\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 279, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270260810852051, Valid: 2.33842134475708\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 279, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238614320755005, Valid: 2.361415147781372\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 279, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307392120361328, Valid: 2.347618579864502\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 279, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317668914794922, Valid: 2.3332018852233887\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 280, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3173177242279053, Valid: 2.328817844390869\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 280, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702677249908447, Valid: 2.3384294509887695\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 280, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2385988235473633, Valid: 2.3613686561584473\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 280, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307368516921997, Valid: 2.34763240814209\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 280, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3176846504211426, Valid: 2.33318829536438\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 281, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171095848083496, Valid: 2.328371047973633\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 281, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702524662017822, Valid: 2.3384082317352295\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 281, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2386116981506348, Valid: 2.361360788345337\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 281, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3073554039001465, Valid: 2.347640037536621\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 281, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3177449703216553, Valid: 2.333216905593872\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 282, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3171005249023438, Valid: 2.328380584716797\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 282, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702598571777344, Valid: 2.3383970260620117\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 282, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2386293411254883, Valid: 2.361346483230591\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 282, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3073458671569824, Valid: 2.347644567489624\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 282, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3177967071533203, Valid: 2.333240509033203\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 283, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170931339263916, Valid: 2.3283886909484863\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 283, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270265817642212, Valid: 2.3383867740631104\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 283, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238647699356079, Valid: 2.3613288402557373\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 283, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3073389530181885, Valid: 2.3476481437683105\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 283, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317841053009033, Valid: 2.3332602977752686\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 284, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170883655548096, Valid: 2.3283963203430176\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 284, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270270586013794, Valid: 2.338379144668579\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 284, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238665819168091, Valid: 2.3613109588623047\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 284, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307333469390869, Valid: 2.3476498126983643\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 284, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317880392074585, Valid: 2.3332767486572266\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 285, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170840740203857, Valid: 2.328401803970337\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 285, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270273447036743, Valid: 2.3383731842041016\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 285, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238682746887207, Valid: 2.361290693283081\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 285, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3073291778564453, Valid: 2.3476510047912598\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 285, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3179140090942383, Valid: 2.3332910537719727\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 286, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170812129974365, Valid: 2.328407049179077\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 286, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702770233154297, Valid: 2.338366985321045\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 286, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238699436187744, Valid: 2.361271858215332\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 286, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307325839996338, Valid: 2.347651958465576\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 286, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317944288253784, Valid: 2.3333024978637695\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 287, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170790672302246, Valid: 2.3284127712249756\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 287, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702794075012207, Valid: 2.3383615016937256\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 287, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387161254882812, Valid: 2.361252784729004\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 287, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307323932647705, Valid: 2.347651243209839\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 287, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317971706390381, Valid: 2.333313465118408\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 288, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.31707763671875, Valid: 2.3284168243408203\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 288, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270280599594116, Valid: 2.3383567333221436\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 288, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387313842773438, Valid: 2.361233949661255\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 288, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307321786880493, Valid: 2.3476507663726807\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 288, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317995071411133, Valid: 2.3333218097686768\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 289, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170764446258545, Valid: 2.328420877456665\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 289, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.268325090408325, Valid: 2.337071180343628\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 289, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2387914657592773, Valid: 2.360908269882202\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3072474002838135, Valid: 2.3475892543792725\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 289, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317838191986084, Valid: 2.3332180976867676\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 290, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170688152313232, Valid: 2.32843017578125\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 290, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270296573638916, Valid: 2.3383734226226807\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 290, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238846778869629, Valid: 2.3611068725585938\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 290, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307298183441162, Valid: 2.347627639770508\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 290, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3178868293762207, Valid: 2.3332502841949463\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 291, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3170716762542725, Valid: 2.328434467315674\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 291, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2702908515930176, Valid: 2.338365316390991\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 291, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2388439178466797, Valid: 2.361100196838379\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 291, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307302236557007, Valid: 2.3476288318634033\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 291, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317924737930298, Valid: 2.3332691192626953\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 292, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317075252532959, Valid: 2.3284387588500977\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 292, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2712669372558594, Valid: 2.335800886154175\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 292, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238818407058716, Valid: 2.3607146739959717\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 292, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.30722975730896, Valid: 2.3474221229553223\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 292, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3178930282592773, Valid: 2.333214282989502\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 293, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.317629814147949, Valid: 2.3290839195251465\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 293, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2704544067382812, Valid: 2.3385367393493652\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 293, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2389657497406006, Valid: 2.36088490486145\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 293, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3072617053985596, Valid: 2.34743070602417\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 293, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317875385284424, Valid: 2.333225727081299\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 294, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3169546127319336, Valid: 2.328348159790039\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 294, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703137397766113, Valid: 2.3384158611297607\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 294, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2389397621154785, Valid: 2.3609328269958496\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 294, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3072586059570312, Valid: 2.347459316253662\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 294, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317927598953247, Valid: 2.3332552909851074\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 295, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3169643878936768, Valid: 2.3283610343933105\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 295, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703123092651367, Valid: 2.3384013175964355\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 295, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238924980163574, Valid: 2.360955238342285\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 295, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.307257890701294, Valid: 2.347480058670044\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 295, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.317969799041748, Valid: 2.333277702331543\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 296, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316972017288208, Valid: 2.3283700942993164\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 296, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703118324279785, Valid: 2.3383896350860596\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 296, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2389159202575684, Valid: 2.3609697818756104\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 296, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3072571754455566, Valid: 2.347496747970581\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 296, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3180062770843506, Valid: 2.333296298980713\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 297, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3169772624969482, Valid: 2.328378200531006\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 297, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703123092651367, Valid: 2.3383805751800537\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 297, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.238909959793091, Valid: 2.3609797954559326\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 297, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3072562217712402, Valid: 2.3475089073181152\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 297, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.318037509918213, Valid: 2.333311080932617\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 298, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316981792449951, Valid: 2.3283846378326416\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 298, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.2703120708465576, Valid: 2.3383727073669434\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 298, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2389063835144043, Valid: 2.360985517501831\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 298, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.30961275100708, Valid: 2.3553106784820557\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 298, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.328446388244629, Valid: 2.340494394302368\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999906539917\n",
      "Epoch 299, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.316049575805664, Valid: 2.3280606269836426\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 299, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.270418643951416, Valid: 2.3384084701538086\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 299, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2419509887695312, Valid: 2.3404901027679443\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n",
      "Epoch 299, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.305692434310913, Valid: 2.3451404571533203\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 299, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3287253379821777, Valid: 2.3308582305908203\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n",
      "Epoch 300, CIFAR-10 Batch 1: \n",
      "Loss = Train: 2.3123154640197754, Valid: 2.32603120803833\n",
      "Accuracy = Train: 0.125 Valid: 0.094200000166893\n",
      "Epoch 300, CIFAR-10 Batch 2: \n",
      "Loss = Train: 2.271782875061035, Valid: 2.339439868927002\n",
      "Accuracy = Train: 0.17500001192092896 Valid: 0.094200000166893\n",
      "Epoch 300, CIFAR-10 Batch 3: \n",
      "Loss = Train: 2.2381513118743896, Valid: 2.3596134185791016\n",
      "Accuracy = Train: 0.20000000298023224 Valid: 0.094200000166893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300, CIFAR-10 Batch 4: \n",
      "Loss = Train: 2.3048083782196045, Valid: 2.3422341346740723\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.09780000150203705\n",
      "Epoch 300, CIFAR-10 Batch 5: \n",
      "Loss = Train: 2.3142597675323486, Valid: 2.331334352493286\n",
      "Accuracy = Train: 0.10000000149011612 Valid: 0.0997999981045723\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                sess.run([optimizer], feed_dict={x: batch_features, y: batch_labels, keep_prob: keep_probability, cost_epoch: epoch})\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}: \\n'.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.09765625\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcaec420160>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
